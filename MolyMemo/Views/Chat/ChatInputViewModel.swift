import SwiftUI
import PhotosUI
import Combine
import AVFoundation

@MainActor
class ChatInputViewModel: ObservableObject {
    // MARK: - Input State
    @Published var inputText: String = ""
    @Published var selectedImage: UIImage? = nil
    @Published var selectedPhotoItem: PhotosPickerItem? = nil
    
    // MARK: - Recording State
    @Published var isRecording: Bool = false
    @Published var isAnimatingRecordingEntry: Bool = false
    @Published var isAnimatingRecordingExit: Bool = false
    @Published var isCanceling: Bool = false
    @Published var audioPower: CGFloat = 0.0
    @Published var recordingTranscript: String = ""
    @Published var inputFrame: CGRect = .zero
    @Published var toolboxFrame: CGRect = .zero
    
    // MARK: - UI State
    @Published var showMenu: Bool = false
    @Published var showSuggestions: Bool = false
    @Published var showCamera: Bool = false
    
    // MARK: - Agent State
    @Published var isAgentTyping: Bool = false
    
    // MARK: - Actions
    var onSend: ((String, UIImage?) -> Void)?
    var onSendImmediate: (() -> UUID?)?  // ç«‹å³å‘é€å ä½æ¶ˆæ¯ï¼Œè¿”å›æ¶ˆæ¯IDç”¨äºåç»­æ›´æ–°
    var onUpdateAndSend: ((UUID, String) -> Void)?  // æ›´æ–°æ¶ˆæ¯å†…å®¹å¹¶è§¦å‘AIå¯¹è¯
    var onRemovePlaceholder: ((UUID) -> Void)?  // åˆ é™¤å ä½æ¶ˆæ¯ï¼ˆç”¨äºè½¬å½•å¤±è´¥æˆ–ç»“æœä¸ºç©ºï¼‰
    var onBoxTap: (() -> Void)?
    var onStopGenerator: (() -> Void)?
    
    // MARK: - Internal
    private let holdToTalkSpeechRecognizer = SpeechRecognizer()
    private var holdToTalkGeneration: Int = 0
    private var holdToTalkASRTask: Task<Void, Never>?
    private var holdToTalkRecognizingWaveTask: Task<Void, Never>?
    /// æ¾æ‰‹åè¿›å…¥â€œè¯†åˆ«ä¸­â€é˜¶æ®µï¼šå¿½ç•¥ recorder stop() å¯¼è‡´çš„éŸ³é‡å½’é›¶ï¼Œé¿å…éŸ³æµªç¬é—´é™æ­¢äº§ç”Ÿå¡é¡¿æ„Ÿ
    private var isHoldToTalkRecognizing: Bool = false
    private var cancellables = Set<AnyCancellable>()
    /// æŒ‰ä½è¯´è¯ï¼šæŒ‰ä¸‹ç¬é—´å°±å¼€å§‹â€œé¢„æ”¶éŸ³/é¢„è½¬å†™â€ï¼Œä½†ä¸ç«‹åˆ»å±•ç¤º overlayï¼ˆé¿å…è½»ç‚¹èšç„¦æ—¶é—ªä¸€ä¸‹ UIï¼‰
    private var isPreCapturingHoldToTalk: Bool = false
    /// å½•éŸ³ç»“æŸåå¾…å›å¡«åˆ°è¾“å…¥æ¡†çš„è½¬å†™æ–‡æœ¬ï¼ˆç”¨äºï¼šè¾“å…¥æ¡†å°šæœªå‡ºç°/å°šåœ¨é€€åœºåŠ¨ç”»æ—¶å»¶è¿Ÿå†™å›ï¼‰
    private var pendingDictationTextForInput: String?
    /// åœæ­¢å½•éŸ³åç­‰å¾… final ç»“æœï¼šåœ¨ overlay é€€åœºå®Œæˆæ—¶å†å†³å®šæ˜¯å¦å›å¡«ï¼ˆé¿å… stop å½“ä¸‹è¯»å–åˆ° partial å¯¼è‡´æ¼å­—ï¼‰
    private var shouldBackfillTranscriptOnOverlayDismiss: Bool = false
    /// hold-to-talk è¿‡ç¨‹ä¸­æŒç»­æ›´æ–°çš„â€œæœ€è¿‘ä¸€æ¬¡è¯†åˆ«æ–‡æœ¬â€ï¼ˆç”¨äº stop åå‘é€ï¼‰
    private var holdToTalkLatestText: String = ""
    
    // MARK: - Computed Properties
    
    /// æ˜¯å¦æœ‰å†…å®¹ï¼ˆæ–‡å­—æˆ–å›¾ç‰‡ï¼‰
    var hasContent: Bool {
        !inputText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty || selectedImage != nil
    }
    
    // MARK: - Methods
    
    init() {
        holdToTalkSpeechRecognizer.requestAuthorization()

        // ç”¨çœŸå®æ”¶éŸ³ level é©±åŠ¨ UIï¼ˆæ¥è‡ª SFSpeechRecognizer çš„è¾“å…¥ bufferï¼‰
        holdToTalkSpeechRecognizer.$audioLevel
            .receive(on: DispatchQueue.main)
            .sink { [weak self] level in
                guard let self else { return }
                // è¯†åˆ«ä¸­é˜¶æ®µï¼šä¸è®© stop() çš„ 0 è¦†ç›–å½“å‰æ³¢åŠ¨ï¼Œé¿å… UI â€œä¸€ä¸‹å­åœä½â€
                guard !self.isHoldToTalkRecognizing else { return }
                self.audioPower = CGFloat(level)
            }
            .store(in: &cancellables)
    }
    
    func sendMessage() {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤â€œä¸­æ­¢â€å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        guard hasContent else { return }

        // åªç”¨ hasContent(=trim åˆ¤ç©º) å†³å®šèƒ½å¦å‘é€ï¼›çœŸæ­£å‘é€å†…å®¹ä¿æŒâ€œåŸå§‹æ–‡æœ¬â€ï¼Œä¸åš trim/æ›¿æ¢ã€‚
        let rawTextToSend = inputText
        onSend?(rawTextToSend, selectedImage)
        
        // Reset State
        // æ³¨æ„ï¼šå‘é€åŠ¨ä½œé€šå¸¸ä¼šè§¦å‘é”®ç›˜é€€åœºï¼ˆå¤±ç„¦ï¼‰ä»¥åŠå¤–å±‚å¸ƒå±€å˜åŒ–ã€‚
        // è¿™é‡Œä¸è¦ç”¨ withAnimation åŒ…è£¹â€œæ¸…ç©ºè¾“å…¥/ç§»é™¤æŒ‰é’®â€ï¼Œé¿å…å‡ºç°æŒ‰é’® transition
        // ä¸é”®ç›˜/å¸ƒå±€åŠ¨ç”»ä¸åŒæ­¥å¯¼è‡´çš„â€œè„±å±‚ã€åŸåœ°æ¶ˆå¤±â€è§‚æ„Ÿã€‚
        inputText = ""
        selectedImage = nil
        selectedPhotoItem = nil
        showSuggestions = false
    }
    
    /// å‘é€å»ºè®®æŒ‡ä»¤ï¼ˆä¸æ¸…ç©ºè¾“å…¥æ¡†ï¼Œä½†å›¾ç‰‡ä¼šä¸€èµ·å‘é€ï¼‰
    func sendSuggestion(_ suggestion: String) {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤â€œä¸­æ­¢â€å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        // æŒ‡ä»¤ç­‰åŒäºç”¨æˆ·å‘å‡ºå»çš„æ–‡å­—ï¼š
        // - æŒ‡ä»¤ +ï¼ˆè‹¥å­˜åœ¨ï¼‰å½“å‰å›¾ç‰‡ä¸€èµ·å‘å‡ºå»
        // - è¾“å…¥æ¡†é‡Œå·²æ‰“çš„å­—ä¿ç•™
        // - å‘å®Œåæ¸…æ‰å›¾ç‰‡ï¼Œè®©è¾“å…¥åŒºå›åˆ°çº¯æ–‡å­—è¾“å…¥çŠ¶æ€
        let imageToSend = selectedImage
        onSend?(suggestion, imageToSend)
        
        // æ¸…æ‰å›¾ç‰‡ï¼Œä½†ä¿ç•™ inputTextï¼ˆç”¨æˆ·å­˜é‡æ‰“å­—ï¼‰
        withAnimation {
            selectedImage = nil
            selectedPhotoItem = nil
            // å‘å®ŒæŒ‡ä»¤åï¼ŒæŒ‰é’®ä¸åº”ç»§ç»­å­˜åœ¨ï¼ˆå³ä½¿è¾“å…¥æ¡†é‡Œè¿˜æœ‰å­˜é‡æ–‡å­—ï¼‰
            showSuggestions = false
        }
    }
    
    func handlePhotoSelection(_ item: PhotosPickerItem?) {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤â€œä¸­æ­¢â€å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        guard let item = item else { return }
        Task {
            if let data = try? await item.loadTransferable(type: Data.self),
               let image = UIImage(data: data) {
                await MainActor.run {
                    withAnimation(.spring(response: 0.3, dampingFraction: 0.8)) {
                        self.selectedImage = image
                        self.showMenu = false // Hide menu after selection
                        self.checkForSuggestions() // Mock suggestion trigger
                    }
                }
            }
        }
    }
    
    func removeImage() {
        // å…è®¸ç§»é™¤å›¾ç‰‡ä¹Ÿä¼šæ”¹å˜ UIï¼Œä½† AI è¾“å…¥æ—¶ UI å·²é”å®šä¸”èœå•/é€‰æ‹©å…¥å£å·²ç¦ç”¨ï¼›
        // è¿™é‡Œä¸å†é¢å¤– guardï¼Œé¿å…å‡ºç°â€œçŠ¶æ€å¡æ­»â€æ— æ³•æ¸…ç†çš„æƒ…å†µã€‚
        withAnimation {
            selectedImage = nil
            selectedPhotoItem = nil
            showSuggestions = false // Hide suggestions when image is removed
        }
    }
    
    func toggleMenu() {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤â€œä¸­æ­¢â€å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        withAnimation(.spring(response: 0.3, dampingFraction: 1.0)) {
            showMenu.toggle()
        }
    }
    
    /// æ¨¡æ‹Ÿè§¦å‘å»ºè®®ï¼ˆä¾‹å¦‚è¾“å…¥äº†æŸäº›å…³é”®è¯æˆ–æ·»åŠ äº†å›¾ç‰‡ï¼‰
    func checkForSuggestions() {
        if hasContent {
            withAnimation {
                showSuggestions = true
            }
        } else {
            withAnimation {
                showSuggestions = false
            }
        }
    }
    
    // MARK: - Recording Logic
    
    func startRecording() {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤"ä¸­æ­¢"å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }

        // ç»Ÿä¸€èµ°â€œé¢„æ”¶éŸ³ -> å±•ç¤º overlayâ€ï¼Œå‡å°‘é‡å¤é€»è¾‘
        beginHoldToTalkPreCaptureIfNeeded()
        revealHoldToTalkOverlayIfPossible()
    }
    
    func stopRecording() {
        // å·²ç»åœ¨é€€åœºè¿‡ç¨‹ä¸­ï¼Œé¿å…é‡å¤è§¦å‘ï¼ˆé‡å¤ stop å¯èƒ½å¯¼è‡´å‘é€ä¸¤æ¬¡ï¼‰
        guard !isAnimatingRecordingExit else { return }

        // ç»“æŸé¢„æ”¶éŸ³çŠ¶æ€ï¼ˆæ— è®ºæ˜¯å¦å·²å±•ç¤º overlayï¼‰
        isPreCapturingHoldToTalk = false
        let shouldSend = !isCanceling
        let genAtStop = holdToTalkGeneration
        holdToTalkASRTask?.cancel()
        holdToTalkASRTask = nil
        holdToTalkRecognizingWaveTask?.cancel()
        holdToTalkRecognizingWaveTask = nil

        // å–æ¶ˆï¼šç«‹å³ stop + é€€åœºï¼ˆä¸è¿›å…¥è¯†åˆ«æ€ï¼‰
        guard shouldSend else {
            holdToTalkSpeechRecognizer.stopRecording()
            holdToTalkLatestText = ""
            recordingTranscript = ""
            isHoldToTalkRecognizing = false
            beginHoldToTalkExit()
            return
        }

        // å…³é”®ï¼šå…ˆæŠŠ UI ç«‹åˆ»åˆ‡åˆ°â€œè¯†åˆ«ä¸­â€ï¼Œå¹¶å¼€å§‹æ³¢åŠ¨ï¼›å½•éŸ³ stop / ç¼–ç  / ä¸Šä¼ æ”¾åˆ°ä¸‹ä¸€å¸§å»åš
        isHoldToTalkRecognizing = true
        recordingTranscript = "è¯†åˆ«ä¸­..."
        startHoldToTalkRecognizingWave()

        holdToTalkASRTask = Task { [weak self] in
            guard let self else { return }
            // è®© SwiftUI å…ˆæŠŠâ€œè¯†åˆ«ä¸­â€¦â€æ¸²æŸ“å‡ºæ¥ï¼Œå†åš stopï¼ˆAudioSession å½’è¿˜/è¯†åˆ«æ”¶å°¾å¯èƒ½ä¼šå¡é¡¿ï¼‰
            await Task.yield()
            // åœæ­¢æœ¬åœ°è¯­éŸ³è¯†åˆ«å¹¶ç­‰å¾… finalï¼Œå°½é‡é¿å…æ¼å­—
            let text = await self.holdToTalkSpeechRecognizer.stopRecordingAndWaitForFinalText(timeoutSeconds: 1.2)
            guard !Task.isCancelled else { return }

            // å¦‚æœæœŸé—´åˆå¼€å§‹äº†æ–°ä¸€è½®æŒ‰ä½è¯´è¯ï¼Œå°±ä¸è¦æŠŠæ—§ç»“æœå‘å‡ºå»
            guard self.holdToTalkGeneration == genAtStop else {
                // æ–°ä¸€è½®å½•éŸ³ä¼šæ¥ç®¡ UIï¼›è¿™é‡Œä»…æ¸…ç†æœ¬è½®è¯†åˆ«é”
                self.isHoldToTalkRecognizing = false
                self.stopHoldToTalkRecognizingWave()
                return
            }

            // åªç”¨ trim åˆ¤ç©ºï¼›å‘é€å†…å®¹ä¿æŒâ€œåŸå§‹æ–‡æœ¬â€
            let rawText = text
            let isEffectivelyEmpty = rawText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty
            if !isEffectivelyEmpty {
                self.recordingTranscript = ""
                self.stopHoldToTalkRecognizingWave()
                self.isHoldToTalkRecognizing = false
                self.beginHoldToTalkExit()
                // è®© UI å…ˆå®Œæˆä¸€å¸§é€€åœº/å¸ƒå±€ï¼Œå†å‘æ¶ˆæ¯ï¼Œé¿å…â€œå¡é¡¿ä¸€ä¸‹â€
                Task { @MainActor in
                    await Task.yield()
                    self.onSend?(rawText, nil)
                }
            } else {
                self.recordingTranscript = ""
                self.stopHoldToTalkRecognizingWave()
                self.isHoldToTalkRecognizing = false
                self.beginHoldToTalkExit()
            }
        }
    }

    /// æ–°çš„åˆ¤å®šé€»è¾‘ï¼šé•¿æŒ‰æˆç«‹åæ‰è¿›å…¥å½•éŸ³ï¼ˆå…ˆå±•ç¤º overlayï¼Œå†å¯åŠ¨å½•éŸ³å¼•æ“ï¼Œé¿å…â€œè¿›å»å‰å¡é¡¿â€ï¼‰
    func startHoldToTalkRecordingFromLongPress() {
        guard !isAgentTyping else { return }
        guard !isRecording else { return }

        // æ¥ç®¡ä¸Šä¸€è½®è¯†åˆ«ä¸­çŠ¶æ€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        isHoldToTalkRecognizing = false
        stopHoldToTalkRecognizingWave()

        // å…¼å®¹ï¼šæŸäº›æ‰‹åŠ¿é“¾è·¯å¯èƒ½â€œé•¿æŒ‰æˆç«‹â€æ‰è§¦å‘ï¼Œè€Œæ²¡æœ‰å…ˆèµ° press-down é¢„æ”¶éŸ³ï¼›
        // è¿™é‡Œç¡®ä¿æœ¬åœ°è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨ï¼Œå¦åˆ™ä¼šå‡ºç°â€œè¿›å…¥å½•éŸ³ UI ä½†æ”¶ä¸åˆ°éŸ³/æ²¡è½¬å†™â€çš„é—®é¢˜ã€‚
        beginHoldToTalkPreCaptureIfNeeded()
        revealHoldToTalkOverlayIfPossible()
    }

    /// å¼€å§‹â€œè¯†åˆ«ä¸­â€çš„å‡éŸ³æµªï¼ˆæ¾æ‰‹åä¿æŒæ³¢åŠ¨æ›´ä¸æ»‘ï¼‰
    private func startHoldToTalkRecognizingWave() {
        holdToTalkRecognizingWaveTask?.cancel()
        // ç«‹å³æŠ¬åˆ°é˜ˆå€¼ä¹‹ä¸Šï¼Œé¿å… VoiceWaveformView åˆ‡åˆ°é™æ€æ¡å¯¼è‡´çš„â€œé¡¿ä¸€ä¸‹â€
        audioPower = max(audioPower, 0.22)
        holdToTalkRecognizingWaveTask = Task { @MainActor in
            var t: Double = 0
            while !Task.isCancelled {
                // ä¿æŒ > 0.01ï¼Œç¡®ä¿ VoiceWaveformView èµ° TimelineView åŠ¨ç”»åˆ†æ”¯
                let base: CGFloat = 0.22
                let a1: CGFloat = 0.10
                let a2: CGFloat = 0.06
                let v = base + a1 * CGFloat(sin(t * 2.2)) + a2 * CGFloat(sin(t * 5.7 + 1.3))
                self.audioPower = max(0.08, min(v, 0.55))
                t += 0.06
                try? await Task.sleep(nanoseconds: 33_000_000) // ~30fps
            }
        }
    }

    private func stopHoldToTalkRecognizingWave() {
        holdToTalkRecognizingWaveTask?.cancel()
        holdToTalkRecognizingWaveTask = nil
    }

    /// å¿«é€Ÿé€€åœºï¼šè¾“å…¥æ¡†ç«‹å³æ¢å¤ï¼Œoverlay è‡ªå·±æ·¡å‡ºå¹¶å›è°ƒ finish
    private func beginHoldToTalkExit() {
        // å…³é”®ï¼šå…ˆæŠŠâ€œé€€åœºæ ‡è®°â€ç½®èµ·æ¥ï¼Œé¿å…å‡ºç° isRecording=false & isAnimatingRecordingExit=false çš„çŸ­æš‚çª—å£
        // å¦åˆ™ SwiftUI å¯èƒ½æŠŠ overlay ä»æ ‘é‡Œç§»é™¤å†æ’å›ï¼Œå¯¼è‡´ overlay çš„ onChange(isExiting) ä¸è§¦å‘ï¼Œä»è€Œå¡ä½ã€‚
        isPreCapturingHoldToTalk = false
        withAnimation(.easeInOut(duration: 0.12)) {
            isAnimatingRecordingExit = true
        }
        // è®©è¾“å…¥æ¡†ç«‹åˆ»å›æ¥ï¼ˆæ›´ä¸æ»‘ï¼‰
        isRecording = false
        // å…œåº•ï¼šä»»ä½•é€€å‡ºéƒ½ç»“æŸâ€œè¯†åˆ«ä¸­é”å®šâ€
        isHoldToTalkRecognizing = false
    }
    
    /// ç”± overlay çš„é€†å‘åŠ¨ç”»ç»“æŸå›è°ƒè§¦å‘ï¼šçœŸæ­£æ”¶èµ· overlay å¹¶æ¢å¤è¾“å…¥æ¡†
    func finishRecordingOverlayDismissal() {
        withAnimation(.easeInOut(duration: 0.1)) {
            // isRecording å·²åœ¨ beginHoldToTalkExit é‡Œæå‰ç½® falseï¼Œç”¨äºâ€œè¾“å…¥æ¡†ç«‹å³å›å½’â€
            isAnimatingRecordingEntry = false
            isAnimatingRecordingExit = false
            isCanceling = false
            audioPower = 0
        }
        // å‘é€åŠ¨ä½œç”± AUC flash å›è°ƒé©±åŠ¨ï¼›è¿™é‡Œä»…è´Ÿè´£æ”¶ UI
    }
    
    func cancelRecording() {
        withAnimation {
            isCanceling = true
        }
        print("[HoldToTalk] ğŸ™… cancel (will stop after 0.3s)")
        // Delay stop to show cancel animation
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) {
             self.stopRecording()
        }
    }

    // MARK: - Hold-to-talk pre-capture (press-down immediately, reveal overlay slightly later)

    /// æŒ‰ä¸‹ç¬é—´è°ƒç”¨ï¼šç«‹åˆ»å¼€å§‹æ”¶éŸ³/è½¬å†™ï¼Œä½†ä¸å±•ç¤º overlayï¼ˆé˜²æ­¢è½»ç‚¹èšç„¦æ—¶ UI é—ªçƒï¼‰ã€‚
    func beginHoldToTalkPreCaptureIfNeeded() {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤"ä¸­æ­¢"å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        guard !isRecording else { return } // å·²åœ¨å½•éŸ³ overlay ä¸­ï¼Œæ— éœ€é‡å¤
        guard !isPreCapturingHoldToTalk else { return }

        // å¦‚æœä¸Šä¸€è½®è¿˜å¤„äºâ€œè¯†åˆ«ä¸­â€ï¼Œè¿™é‡Œéœ€è¦æ¥ç®¡ UIï¼šæ¢å¤çœŸå®éŸ³é‡é©±åŠ¨å¹¶åœæ‰å‡éŸ³æµª
        isHoldToTalkRecognizing = false
        stopHoldToTalkRecognizingWave()

        isPreCapturingHoldToTalk = true
        isCanceling = false
        recordingTranscript = "" // overlay å½“å‰ä¸å±•ç¤º transcriptï¼Œä½†ç•™ç€è°ƒè¯•
        audioPower = 0.0
        holdToTalkLatestText = ""

        holdToTalkGeneration &+= 1
        let gen = holdToTalkGeneration
        holdToTalkASRTask?.cancel()
        holdToTalkASRTask = nil

        print("[HoldToTalk] press down -> start pre-capture (gen=\(gen))")
        // ç›´æ¥å¯åŠ¨ iOS æœ¬åœ°è¯­éŸ³è¯†åˆ«ï¼ˆå†…éƒ¨å·²ç”¨ç‹¬ç«‹é˜Ÿåˆ—å¤„ç† AudioSession/Engineï¼‰
        holdToTalkSpeechRecognizer.startRecording { [weak self] text in
            guard let self else { return }
            // è‹¥è¿™ä¸€è½®å·²è¢«æ–°ä¸€è½®æ›¿ä»£ï¼Œä¸¢å¼ƒå›è°ƒ
            guard self.holdToTalkGeneration == gen else { return }
            self.holdToTalkLatestText = text
        }
    }

    /// é•¿æŒ‰è¢«åˆ¤å®š/éœ€è¦å±•ç¤º UI æ—¶è°ƒç”¨ï¼šæŠŠ overlay æ‹‰èµ·æ¥ï¼Œä½†ä¸ä¼šé‡å¯æ”¶éŸ³ã€‚
    func revealHoldToTalkOverlayIfPossible() {
        guard !isAgentTyping else { return }
        guard isPreCapturingHoldToTalk else { return }
        guard !isRecording else { return }

        // æ³¨æ„ï¼šä¸å»ºè®®åœ¨ withAnimation ä¸­ä¿®æ”¹ isRecordingï¼Œ
        // å¦åˆ™æŸäº›å¸ƒå±€è®¡ç®—å¯èƒ½ä¼šåœ¨åŠ¨ç”»ä¸­é€”å‘ç”Ÿå˜åŒ–ã€‚
        isAnimatingRecordingEntry = true
        isAnimatingRecordingExit = false
        isRecording = true
        isCanceling = false
        // recordingTranscript ç»´æŒå½“å‰å€¼ï¼ˆå¯èƒ½å·²ç»æœ‰éƒ¨åˆ†è½¬å†™ï¼‰

        // è§¦æ„Ÿï¼šä»…åœ¨â€œçœŸæ­£è¿›å…¥å½•éŸ³æ€â€æ—¶ç»™ä¸€æ¬¡ç¡®è®¤ï¼ˆæŒ‰ä¸‹ç¬é—´å·²æœ‰ä¸€æ¬¡è§¦æ„Ÿï¼Œè¿™é‡Œæ›´è½»ä¸€ç‚¹ï¼‰
        HapticFeedback.impact(style: .medium, intensity: 0.7)
    }

    /// è½»ç‚¹/æ»‘åŠ¨æ‰“æ–­æ—¶è°ƒç”¨ï¼šåœæ­¢é¢„æ”¶éŸ³ä¸”ä¸å±•ç¤º overlayã€ä¸å‘é€ä»»ä½•æ–‡å­—ã€‚
    func stopHoldToTalkPreCaptureIfNeeded() {
        guard isPreCapturingHoldToTalk else { return }
        isPreCapturingHoldToTalk = false
        holdToTalkASRTask?.cancel()
        holdToTalkASRTask = nil
        holdToTalkSpeechRecognizer.stopRecording()
        holdToTalkLatestText = ""
        recordingTranscript = ""
        audioPower = 0.0
        isCanceling = false
        print("[HoldToTalk] pre-capture stopped (no overlay) -> deleted file")
    }
    
    func updateDragLocation(_ location: CGPoint, in bounds: CGRect) {
        // ç®€å•çš„å‘ä¸Šæ‹–åŠ¨å–æ¶ˆåˆ¤å®š
        // å¦‚æœæ‰‹æŒ‡å‘ä¸Šç§»åŠ¨è¶…è¿‡ä¸€å®šè·ç¦»ï¼ˆä¾‹å¦‚è¾“å…¥æ¡†ä¸Šæ–¹ 50ptï¼‰
        if location.y < -50 {
            if !isCanceling {
                withAnimation { isCanceling = true }
            }
        } else {
            if isCanceling {
                withAnimation { isCanceling = false }
            }
        }
    }

    // MARK: - Dictation backfill

    /// æŠŠå½•éŸ³è½¬å†™ç»“æœå†™å›è¾“å…¥æ¡†ï¼š
    /// - è‹¥è¾“å…¥æ¡†å·²æœ‰æ–‡å­—ï¼šè¿½åŠ ï¼ˆä¸åšæ‰‹åŠ¨æ‹¼ç©ºæ ¼/trimï¼Œä¿æŒåŸå§‹æ–‡æœ¬ï¼‰
    /// - è‹¥è¾“å…¥æ¡†ä¸ºç©ºï¼šç›´æ¥å†™å…¥
    private func applyPendingDictationTextToInputIfNeeded() {
        guard let text = pendingDictationTextForInput,
              !text.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty
        else { return }
        pendingDictationTextForInput = nil

        if inputText.isEmpty {
            inputText = text
        } else {
            inputText = inputText + text
        }
    }
}
