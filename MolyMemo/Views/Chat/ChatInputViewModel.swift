import SwiftUI
import PhotosUI
import Combine
import AVFoundation

@MainActor
class ChatInputViewModel: ObservableObject {
    // MARK: - Input State
    @Published var inputText: String = ""
    @Published var selectedImage: UIImage? = nil
    @Published var selectedPhotoItem: PhotosPickerItem? = nil
    
    // MARK: - Recording State
    @Published var isRecording: Bool = false
    @Published var isAnimatingRecordingEntry: Bool = false
    @Published var isAnimatingRecordingExit: Bool = false
    @Published var isCanceling: Bool = false
    @Published var audioPower: CGFloat = 0.0
    @Published var recordingTranscript: String = ""
    @Published var inputFrame: CGRect = .zero
    @Published var toolboxFrame: CGRect = .zero
    
    // MARK: - UI State
    @Published var showMenu: Bool = false
    @Published var showSuggestions: Bool = false
    @Published var showCamera: Bool = false
    
    // MARK: - Agent State
    @Published var isAgentTyping: Bool = false
    
    // MARK: - Actions
    var onSend: ((String, UIImage?) -> Void)?
    var onSendImmediate: (() -> UUID?)?  // ç«‹å³å‘é€å ä½æ¶ˆæ¯ï¼Œè¿”å›æ¶ˆæ¯IDç”¨äºåç»­æ›´æ–°
    var onUpdateAndSend: ((UUID, String) -> Void)?  // æ›´æ–°æ¶ˆæ¯å†…å®¹å¹¶è§¦å‘AIå¯¹è¯ï¼ˆéè¯­éŸ³ WSï¼‰
    var onUpdatePlaceholderText: ((UUID, String) -> Void)?  // ä»…æ›´æ–°ç”¨æˆ·å ä½æ°”æ³¡ï¼ˆè¯­éŸ³å®æ—¶è½¬å†™ï¼‰
    var onRemovePlaceholder: ((UUID) -> Void)?  // åˆ é™¤å ä½æ¶ˆæ¯ï¼ˆç”¨äºè½¬å½•å¤±è´¥æˆ–ç»“æœä¸ºç©ºï¼‰
    /// è¯­éŸ³ WSï¼šå¼€å§‹ä¸€æ¡æ–°çš„ AI å ä½æ¶ˆæ¯ï¼ˆè¿”å› agent messageIdï¼‰ï¼Œå¹¶è¿›å…¥â€œæ‰“å­—ä¸­â€æ€
    var onBeginVoiceAgentMessage: (() -> UUID?)?
    /// è¯­éŸ³ WSï¼šæŠŠåç«¯ chunkï¼ˆdeltaï¼‰å›å¡«åˆ°æŒ‡å®š agent message
    var onApplyVoiceAgentOutput: ((UUID, BackendChatStructuredOutput) -> Void)?
    /// è¯­éŸ³ WSï¼šç»“æŸ agent messageï¼ˆå®Œæˆ/è½åº“/é€€å‡ºæ‰“å­—ä¸­ï¼‰
    var onEndVoiceAgentMessage: ((UUID) -> Void)?
    /// è¯­éŸ³ WSï¼šæµå¼é”™è¯¯ï¼ˆè‹¥ messageId=nil è¡¨ç¤ºå°šæœªåˆ›å»º agent å ä½ï¼‰
    var onVoiceAgentError: ((UUID?, String) -> Void)?
    /// æµ‹è¯•ï¼šæŠŠâ€œåŸå§‹å½•éŸ³â€æ’å…¥èŠå¤©ï¼ˆç”¨æˆ·æ°”æ³¡ï¼Œå¸¦æœ¬åœ°å¯æ’­æ”¾éŸ³é¢‘ï¼‰ã€‚
    /// - ä»…ç”¨äºéªŒè¯æŒ‰ä½è¯´è¯çš„éŸ³é¢‘æ˜¯å¦æ­£ç¡®é‡‡é›†ï¼›ä¸å½±å“ç°æœ‰è½¬å†™/AI é“¾è·¯ã€‚
    var onInsertHoldToTalkRawAudio: ((URL) -> Void)?
    var onBoxTap: (() -> Void)?
    var onStopGenerator: (() -> Void)?
    
    // MARK: - Internal
    private let holdToTalkRecorder = HoldToTalkPCMRecorder()
    private var holdToTalkVoiceSession: ChatVoiceInputService.Session?
    private var holdToTalkGeneration: Int = 0
    private var holdToTalkASRTask: Task<Void, Never>?
    private var holdToTalkRecognizingWaveTask: Task<Void, Never>?
    private var holdToTalkSendLoopTask: Task<Void, Never>?
    private var holdToTalkReceiveLoopTask: Task<Void, Never>?
    /// é¢„æ”¶éŸ³å¯åŠ¨ä»»åŠ¡ï¼šç”¨äºâ€œå¿«é€Ÿå–æ¶ˆ/ç»“æŸâ€æ—¶é˜»æ­¢å¼‚æ­¥æ’å…¥å ä½æ°”æ³¡
    private var holdToTalkStartupTask: Task<Void, Never>?
    private var holdToTalkPlaceholderMessageId: UUID?
    private var holdToTalkAgentMessageId: UUID?
    private var holdToTalkLatestASRText: String = ""
    private var holdToTalkLatestASRIsFinal: Bool = false
    /// PCM å‘é€ç¼“å†²ï¼šé¿å… WS åˆšå»ºç«‹æ—¶ send() å¤±è´¥å¯¼è‡´å‰é¢éŸ³é¢‘ä¸¢å¤±ï¼ˆæ¼å­—ï¼‰
    private var holdToTalkPCMBacklog: PCMBacklog?
    /// æ¾æ‰‹åè¿›å…¥â€œè¯†åˆ«ä¸­â€é˜¶æ®µï¼šå¿½ç•¥ recorder stop() å¯¼è‡´çš„éŸ³é‡å½’é›¶ï¼Œé¿å…éŸ³æµªç¬é—´é™æ­¢äº§ç”Ÿå¡é¡¿æ„Ÿ
    private var isHoldToTalkRecognizing: Bool = false
    private var cancellables = Set<AnyCancellable>()
    /// æŒ‰ä½è¯´è¯ï¼šæŒ‰ä¸‹ç¬é—´å°±å¼€å§‹â€œé¢„æ”¶éŸ³/é¢„è½¬å†™â€ï¼Œä½†ä¸ç«‹åˆ»å±•ç¤º overlayï¼ˆé¿å…è½»ç‚¹èšç„¦æ—¶é—ªä¸€ä¸‹ UIï¼‰
    private var isPreCapturingHoldToTalk: Bool = false
    /// å½•éŸ³ç»“æŸåå¾…å›å¡«åˆ°è¾“å…¥æ¡†çš„è½¬å†™æ–‡æœ¬ï¼ˆç”¨äºï¼šè¾“å…¥æ¡†å°šæœªå‡ºç°/å°šåœ¨é€€åœºåŠ¨ç”»æ—¶å»¶è¿Ÿå†™å›ï¼‰
    private var pendingDictationTextForInput: String?
    /// åœæ­¢å½•éŸ³åç­‰å¾… final ç»“æœï¼šåœ¨ overlay é€€åœºå®Œæˆæ—¶å†å†³å®šæ˜¯å¦å›å¡«ï¼ˆé¿å… stop å½“ä¸‹è¯»å–åˆ° partial å¯¼è‡´æ¼å­—ï¼‰
    private var shouldBackfillTranscriptOnOverlayDismiss: Bool = false
    /// hold-to-talk è¿‡ç¨‹ä¸­æŒç»­æ›´æ–°çš„â€œæœ€è¿‘ä¸€æ¬¡è¯†åˆ«æ–‡æœ¬â€ï¼ˆç”¨äº stop åå‘é€ï¼‰
    private var holdToTalkLatestText: String = ""
    /// æµ‹è¯•ï¼šæ±‡æ€»æœ¬æ¬¡æŒ‰ä½è¯´è¯çš„å®Œæ•´ PCMï¼ˆ16k/16bit/monoï¼‰ã€‚
    /// - ç”±äº sendLoop ä¼š drain PCM å¹¶æ¸…ç©º recorder ç¼“å†²ï¼Œæ‰€ä»¥éœ€è¦é¢å¤–ç´¯ç§¯ä¸€ä»½ã€‚
    /// - ä»…ç”¨äºæœ¬åœ°è½ç›˜æˆ wav å¹¶å±•ç¤ºï¼›ä¸ä¼šå½±å“ WS çš„å‘é€æ•°æ®ã€‚
    private var holdToTalkFullPCM: Data = Data()
    
    // MARK: - Computed Properties
    
    /// æ˜¯å¦æœ‰å†…å®¹ï¼ˆæ–‡å­—æˆ–å›¾ç‰‡ï¼‰
    var hasContent: Bool {
        !inputText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty || selectedImage != nil
    }
    
    // MARK: - Methods
    
    init() {
        // ç”¨çœŸå®æ”¶éŸ³ level é©±åŠ¨ UIï¼ˆæ¥è‡ªéº¦å…‹é£ PCM é‡‡é›†ï¼‰
        holdToTalkRecorder.$audioLevel
            .receive(on: DispatchQueue.main)
            .sink { [weak self] level in
                guard let self else { return }
                // è¯†åˆ«ä¸­é˜¶æ®µï¼šä¸è®© stop() çš„ 0 è¦†ç›–å½“å‰æ³¢åŠ¨ï¼Œé¿å… UI â€œä¸€ä¸‹å­åœä½â€
                guard !self.isHoldToTalkRecognizing else { return }
                self.audioPower = CGFloat(level)
            }
            .store(in: &cancellables)
    }
    
    func sendMessage() {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤â€œä¸­æ­¢â€å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        guard hasContent else { return }

        // åªç”¨ hasContent(=trim åˆ¤ç©º) å†³å®šèƒ½å¦å‘é€ï¼›çœŸæ­£å‘é€å†…å®¹ä¿æŒâ€œåŸå§‹æ–‡æœ¬â€ï¼Œä¸åš trim/æ›¿æ¢ã€‚
        let rawTextToSend = inputText
        onSend?(rawTextToSend, selectedImage)
        
        // Reset State
        // æ³¨æ„ï¼šå‘é€åŠ¨ä½œé€šå¸¸ä¼šè§¦å‘é”®ç›˜é€€åœºï¼ˆå¤±ç„¦ï¼‰ä»¥åŠå¤–å±‚å¸ƒå±€å˜åŒ–ã€‚
        // è¿™é‡Œä¸è¦ç”¨ withAnimation åŒ…è£¹â€œæ¸…ç©ºè¾“å…¥/ç§»é™¤æŒ‰é’®â€ï¼Œé¿å…å‡ºç°æŒ‰é’® transition
        // ä¸é”®ç›˜/å¸ƒå±€åŠ¨ç”»ä¸åŒæ­¥å¯¼è‡´çš„â€œè„±å±‚ã€åŸåœ°æ¶ˆå¤±â€è§‚æ„Ÿã€‚
        inputText = ""
        selectedImage = nil
        selectedPhotoItem = nil
        showSuggestions = false
    }
    
    /// å‘é€å»ºè®®æŒ‡ä»¤ï¼ˆä¸æ¸…ç©ºè¾“å…¥æ¡†ï¼Œä½†å›¾ç‰‡ä¼šä¸€èµ·å‘é€ï¼‰
    func sendSuggestion(_ suggestion: String) {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤â€œä¸­æ­¢â€å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        // æŒ‡ä»¤ç­‰åŒäºç”¨æˆ·å‘å‡ºå»çš„æ–‡å­—ï¼š
        // - æŒ‡ä»¤ +ï¼ˆè‹¥å­˜åœ¨ï¼‰å½“å‰å›¾ç‰‡ä¸€èµ·å‘å‡ºå»
        // - è¾“å…¥æ¡†é‡Œå·²æ‰“çš„å­—ä¿ç•™
        // - å‘å®Œåæ¸…æ‰å›¾ç‰‡ï¼Œè®©è¾“å…¥åŒºå›åˆ°çº¯æ–‡å­—è¾“å…¥çŠ¶æ€
        let imageToSend = selectedImage
        onSend?(suggestion, imageToSend)
        
        // æ¸…æ‰å›¾ç‰‡ï¼Œä½†ä¿ç•™ inputTextï¼ˆç”¨æˆ·å­˜é‡æ‰“å­—ï¼‰
        withAnimation {
            selectedImage = nil
            selectedPhotoItem = nil
            // å‘å®ŒæŒ‡ä»¤åï¼ŒæŒ‰é’®ä¸åº”ç»§ç»­å­˜åœ¨ï¼ˆå³ä½¿è¾“å…¥æ¡†é‡Œè¿˜æœ‰å­˜é‡æ–‡å­—ï¼‰
            showSuggestions = false
        }
    }
    
    func handlePhotoSelection(_ item: PhotosPickerItem?) {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤â€œä¸­æ­¢â€å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        guard let item = item else { return }
        Task {
            if let data = try? await item.loadTransferable(type: Data.self),
               let image = UIImage(data: data) {
                await MainActor.run {
                    withAnimation(.spring(response: 0.3, dampingFraction: 0.8)) {
                        self.selectedImage = image
                        self.showMenu = false // Hide menu after selection
                        self.checkForSuggestions() // Mock suggestion trigger
                    }
                }
            }
        }
    }
    
    func removeImage() {
        // å…è®¸ç§»é™¤å›¾ç‰‡ä¹Ÿä¼šæ”¹å˜ UIï¼Œä½† AI è¾“å…¥æ—¶ UI å·²é”å®šä¸”èœå•/é€‰æ‹©å…¥å£å·²ç¦ç”¨ï¼›
        // è¿™é‡Œä¸å†é¢å¤– guardï¼Œé¿å…å‡ºç°â€œçŠ¶æ€å¡æ­»â€æ— æ³•æ¸…ç†çš„æƒ…å†µã€‚
        withAnimation {
            selectedImage = nil
            selectedPhotoItem = nil
            showSuggestions = false // Hide suggestions when image is removed
        }
    }
    
    func toggleMenu() {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤â€œä¸­æ­¢â€å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        withAnimation(.spring(response: 0.3, dampingFraction: 1.0)) {
            showMenu.toggle()
        }
    }
    
    /// æ¨¡æ‹Ÿè§¦å‘å»ºè®®ï¼ˆä¾‹å¦‚è¾“å…¥äº†æŸäº›å…³é”®è¯æˆ–æ·»åŠ äº†å›¾ç‰‡ï¼‰
    func checkForSuggestions() {
        if hasContent {
            withAnimation {
                showSuggestions = true
            }
        } else {
            withAnimation {
                showSuggestions = false
            }
        }
    }
    
    // MARK: - Recording Logic
    
    func startRecording() {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤"ä¸­æ­¢"å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }

        // ç»Ÿä¸€èµ°â€œé¢„æ”¶éŸ³ -> å±•ç¤º overlayâ€ï¼Œå‡å°‘é‡å¤é€»è¾‘
        beginHoldToTalkPreCaptureIfNeeded()
        revealHoldToTalkOverlayIfPossible()
    }
    
    func stopRecording() {
        // å·²ç»åœ¨é€€åœºè¿‡ç¨‹ä¸­ï¼Œé¿å…é‡å¤è§¦å‘ï¼ˆé‡å¤ stop å¯èƒ½å¯¼è‡´å‘é€ä¸¤æ¬¡ï¼‰
        guard !isAnimatingRecordingExit else { return }

        // ç»“æŸé¢„æ”¶éŸ³çŠ¶æ€ï¼ˆæ— è®ºæ˜¯å¦å·²å±•ç¤º overlayï¼‰
        isPreCapturingHoldToTalk = false
        let shouldSend = !isCanceling
        let genAtStop = holdToTalkGeneration
        holdToTalkASRTask?.cancel()
        holdToTalkASRTask = nil
        holdToTalkRecognizingWaveTask?.cancel()
        holdToTalkRecognizingWaveTask = nil
        holdToTalkSendLoopTask?.cancel()
        holdToTalkSendLoopTask = nil
        holdToTalkStartupTask?.cancel()
        holdToTalkStartupTask = nil

        // å–æ¶ˆï¼šç«‹å³ stop + é€€åœºï¼ˆä¸è¿›å…¥è¯†åˆ«æ€ï¼‰
        guard shouldSend else {
            // å–æ¶ˆéœ€è¦å‘ŠçŸ¥åç«¯å¹¶é‡Šæ”¾éº¦å…‹é£
            let placeholderId = holdToTalkPlaceholderMessageId
            holdToTalkPlaceholderMessageId = nil
            holdToTalkAgentMessageId = nil
            holdToTalkLatestText = ""
            holdToTalkLatestASRText = ""
            holdToTalkLatestASRIsFinal = false
            recordingTranscript = ""
            isHoldToTalkRecognizing = false
            holdToTalkReceiveLoopTask?.cancel()
            holdToTalkReceiveLoopTask = nil
            Task.detached { [weak self] in
                guard let self else { return }
                if let s = await MainActor.run(body: { self.holdToTalkVoiceSession }) {
                    try? await s.sendCancel()
                    await s.close()
                }
                _ = await MainActor.run { self.holdToTalkRecorder.stop(discard: true) }
                await MainActor.run { self.holdToTalkVoiceSession = nil }
            }
            if let placeholderId {
                onRemovePlaceholder?(placeholderId)
            }
            beginHoldToTalkExit()
            return
        }

        // âœ… æ¾æ‰‹å‘é€ï¼šä¸å†æ’å…¥â€œè¯†åˆ«ä¸­...â€æ°”æ³¡ã€‚
        // - ç”¨æˆ·æ°”æ³¡ï¼šç”± asr_result/asr_complete å®æ—¶æ›´æ–°å ä½æ¶ˆæ¯å†…å®¹
        // - AI æ°”æ³¡ï¼šç”± `/api/v1/chat/voice` çš„ assistant chunk æŒ‰æ™®é€š chat ç»“æ„åŒ–å›å¡«
        recordingTranscript = ""
        beginHoldToTalkExit()

        holdToTalkASRTask = Task { [weak self] in
            guard let self else { return }
            // è®© SwiftUI å…ˆå®Œæˆä¸€å¸§é€€åœº/å¸ƒå±€ï¼Œå†è¿›è¡Œ stopï¼ˆAudioSession å½’è¿˜/æ”¶å°¾å¯èƒ½ä¼šå¡é¡¿ï¼‰
            await Task.yield()
            guard !Task.isCancelled else { return }
            // å¦‚æœæœŸé—´åˆå¼€å§‹äº†æ–°ä¸€è½®æŒ‰ä½è¯´è¯ï¼Œå°±ä¸è¦å½±å“æ–°ä¸€è½®
            guard self.holdToTalkGeneration == genAtStop else { return }
            await self.finishBackendHoldToTalkAndSendAudioDone(genAtStop: genAtStop)
        }
    }

    /// æ–°çš„åˆ¤å®šé€»è¾‘ï¼šé•¿æŒ‰æˆç«‹åæ‰è¿›å…¥å½•éŸ³ï¼ˆå…ˆå±•ç¤º overlayï¼Œå†å¯åŠ¨å½•éŸ³å¼•æ“ï¼Œé¿å…â€œè¿›å»å‰å¡é¡¿â€ï¼‰
    func startHoldToTalkRecordingFromLongPress() {
        guard !isAgentTyping else { return }
        guard !isRecording else { return }

        // æ¥ç®¡ä¸Šä¸€è½®è¯†åˆ«ä¸­çŠ¶æ€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        isHoldToTalkRecognizing = false
        stopHoldToTalkRecognizingWave()

        // å…¼å®¹ï¼šæŸäº›æ‰‹åŠ¿é“¾è·¯å¯èƒ½â€œé•¿æŒ‰æˆç«‹â€æ‰è§¦å‘ï¼Œè€Œæ²¡æœ‰å…ˆèµ° press-down é¢„æ”¶éŸ³ï¼›
        // è¿™é‡Œç¡®ä¿æœ¬åœ°è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨ï¼Œå¦åˆ™ä¼šå‡ºç°â€œè¿›å…¥å½•éŸ³ UI ä½†æ”¶ä¸åˆ°éŸ³/æ²¡è½¬å†™â€çš„é—®é¢˜ã€‚
        beginHoldToTalkPreCaptureIfNeeded()
        revealHoldToTalkOverlayIfPossible()
    }

    /// å¼€å§‹â€œè¯†åˆ«ä¸­â€çš„å‡éŸ³æµªï¼ˆæ¾æ‰‹åä¿æŒæ³¢åŠ¨æ›´ä¸æ»‘ï¼‰
    private func startHoldToTalkRecognizingWave() {
        holdToTalkRecognizingWaveTask?.cancel()
        // ç«‹å³æŠ¬åˆ°é˜ˆå€¼ä¹‹ä¸Šï¼Œé¿å… VoiceWaveformView åˆ‡åˆ°é™æ€æ¡å¯¼è‡´çš„â€œé¡¿ä¸€ä¸‹â€
        audioPower = max(audioPower, 0.22)
        holdToTalkRecognizingWaveTask = Task { @MainActor in
            var t: Double = 0
            while !Task.isCancelled {
                // ä¿æŒ > 0.01ï¼Œç¡®ä¿ VoiceWaveformView èµ° TimelineView åŠ¨ç”»åˆ†æ”¯
                let base: CGFloat = 0.22
                let a1: CGFloat = 0.10
                let a2: CGFloat = 0.06
                let v = base + a1 * CGFloat(sin(t * 2.2)) + a2 * CGFloat(sin(t * 5.7 + 1.3))
                self.audioPower = max(0.08, min(v, 0.55))
                t += 0.06
                try? await Task.sleep(nanoseconds: 33_000_000) // ~30fps
            }
        }
    }

    private func stopHoldToTalkRecognizingWave() {
        holdToTalkRecognizingWaveTask?.cancel()
        holdToTalkRecognizingWaveTask = nil
    }

    /// å¿«é€Ÿé€€åœºï¼šè¾“å…¥æ¡†ç«‹å³æ¢å¤ï¼Œoverlay è‡ªå·±æ·¡å‡ºå¹¶å›è°ƒ finish
    private func beginHoldToTalkExit() {
        // å…³é”®ï¼šå…ˆæŠŠâ€œé€€åœºæ ‡è®°â€ç½®èµ·æ¥ï¼Œé¿å…å‡ºç° isRecording=false & isAnimatingRecordingExit=false çš„çŸ­æš‚çª—å£
        // å¦åˆ™ SwiftUI å¯èƒ½æŠŠ overlay ä»æ ‘é‡Œç§»é™¤å†æ’å›ï¼Œå¯¼è‡´ overlay çš„ onChange(isExiting) ä¸è§¦å‘ï¼Œä»è€Œå¡ä½ã€‚
        isPreCapturingHoldToTalk = false
        withAnimation(.easeInOut(duration: 0.12)) {
            isAnimatingRecordingExit = true
        }
        // è®©è¾“å…¥æ¡†ç«‹åˆ»å›æ¥ï¼ˆæ›´ä¸æ»‘ï¼‰
        isRecording = false
        // å…œåº•ï¼šä»»ä½•é€€å‡ºéƒ½ç»“æŸâ€œè¯†åˆ«ä¸­é”å®šâ€
        isHoldToTalkRecognizing = false
    }
    
    /// ç”± overlay çš„é€†å‘åŠ¨ç”»ç»“æŸå›è°ƒè§¦å‘ï¼šçœŸæ­£æ”¶èµ· overlay å¹¶æ¢å¤è¾“å…¥æ¡†
    func finishRecordingOverlayDismissal() {
        withAnimation(.easeInOut(duration: 0.1)) {
            // isRecording å·²åœ¨ beginHoldToTalkExit é‡Œæå‰ç½® falseï¼Œç”¨äºâ€œè¾“å…¥æ¡†ç«‹å³å›å½’â€
            isAnimatingRecordingEntry = false
            isAnimatingRecordingExit = false
            isCanceling = false
            audioPower = 0
        }
        // å‘é€åŠ¨ä½œç”± AUC flash å›è°ƒé©±åŠ¨ï¼›è¿™é‡Œä»…è´Ÿè´£æ”¶ UI
    }
    
    func cancelRecording() {
        withAnimation {
            isCanceling = true
        }
        print("[HoldToTalk] ğŸ™… cancel (will stop after 0.3s)")
        // Delay stop to show cancel animation
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) {
             self.stopRecording()
        }
    }

    /// åœæ­¢â€œè¯­éŸ³ WS çš„ AI å›å¤æµâ€ï¼ˆç”¨äºï¼šç”¨æˆ·ç‚¹äº†â€œä¸­æ­¢â€æŒ‰é’®ï¼‰ã€‚
    /// - å¤‡æ³¨ï¼šæ™®é€š chat çš„ä¸­æ­¢ç”± AppState.stopGeneration() å¤„ç†ï¼›è¿™é‡Œè¡¥é½ voice WS çš„å–æ¶ˆã€‚
    func stopVoiceAssistantIfNeeded() {
        Task.detached { [weak self] in
            guard let self else { return }
            if let s = await MainActor.run(body: { self.holdToTalkVoiceSession }) {
                try? await s.sendCancel()
            }
            await self.closeHoldToTalkSession()
        }
    }

    // MARK: - Hold-to-talk pre-capture (press-down immediately, reveal overlay slightly later)

    /// æŒ‰ä¸‹ç¬é—´è°ƒç”¨ï¼šç«‹åˆ»å¼€å§‹æ”¶éŸ³/è½¬å†™ï¼Œä½†ä¸å±•ç¤º overlayï¼ˆé˜²æ­¢è½»ç‚¹èšç„¦æ—¶ UI é—ªçƒï¼‰ã€‚
    func beginHoldToTalkPreCaptureIfNeeded() {
        // AI è¾“å…¥è¿‡ç¨‹ä¸­ï¼šè¾“å…¥åŒºé™¤"ä¸­æ­¢"å¤–å…¨éƒ¨ç¦ç”¨
        guard !isAgentTyping else { return }
        guard !isRecording else { return } // å·²åœ¨å½•éŸ³ overlay ä¸­ï¼Œæ— éœ€é‡å¤
        guard !isPreCapturingHoldToTalk else { return }

        // å¦‚æœä¸Šä¸€è½®è¿˜å¤„äºâ€œè¯†åˆ«ä¸­â€ï¼Œè¿™é‡Œéœ€è¦æ¥ç®¡ UIï¼šæ¢å¤çœŸå®éŸ³é‡é©±åŠ¨å¹¶åœæ‰å‡éŸ³æµª
        isHoldToTalkRecognizing = false
        stopHoldToTalkRecognizingWave()

        isPreCapturingHoldToTalk = true
        isCanceling = false
        recordingTranscript = ""
        audioPower = 0.0
        holdToTalkLatestText = ""
        holdToTalkLatestASRText = ""
        holdToTalkLatestASRIsFinal = false
        holdToTalkAgentMessageId = nil

        holdToTalkGeneration &+= 1
        let gen = holdToTalkGeneration
        holdToTalkASRTask?.cancel()
        holdToTalkASRTask = nil
        holdToTalkSendLoopTask?.cancel()
        holdToTalkSendLoopTask = nil
        holdToTalkReceiveLoopTask?.cancel()
        holdToTalkReceiveLoopTask = nil
        holdToTalkStartupTask?.cancel()
        holdToTalkStartupTask = nil
        holdToTalkVoiceSession = nil
        holdToTalkPlaceholderMessageId = nil
        holdToTalkPCMBacklog = PCMBacklog()
        holdToTalkFullPCM = Data()

        print("[HoldToTalk] press down -> start pre-capture (gen=\(gen))")

        // âœ… æ”¹ä¸ºåç«¯è¯­éŸ³æµå¼è¯†åˆ«ï¼šæœ¬åœ°ä»…è´Ÿè´£é‡‡é›† PCMï¼Œè½¬å†™ç”±åç«¯è¿”å› asr_result/asr_complete
        holdToTalkStartupTask = Task { [weak self] in
            guard let self else { return }
            do {
                // 1) å»ºç«‹ WS
                let session = try ChatVoiceInputService.makeSession(contactId: nil)
                // ç”¨æˆ·å¯èƒ½å·²ç»å¿«é€Ÿæ¾æ‰‹/å–æ¶ˆï¼šè¿™æ—¶ä¸è¦å†ç»§ç»­ï¼Œä¹Ÿä¸è¦æ’å…¥å ä½æ°”æ³¡
                let stillValidAfterConnect = await MainActor.run {
                    self.holdToTalkGeneration == gen && self.isPreCapturingHoldToTalk && !self.isAgentTyping
                }
                guard stillValidAfterConnect, !Task.isCancelled else {
                    await session.close()
                    return
                }
                self.holdToTalkVoiceSession = session
                session.start()

                // 2) å¼€å§‹å½• PCMï¼ˆåŒ…å«éº¦å…‹é£æƒé™è¯·æ±‚ä¸ AudioSession é…ç½®ï¼‰
                try await self.holdToTalkRecorder.start()
                let stillValidAfterRecorder = await MainActor.run {
                    self.holdToTalkGeneration == gen && self.isPreCapturingHoldToTalk && !self.isAgentTyping
                }
                guard stillValidAfterRecorder, !Task.isCancelled else {
                    await session.close()
                    _ = self.holdToTalkRecorder.stop(discard: true)
                    return
                }

                // 3) ä»…åœ¨â€œä»å¤„äºé¢„æ”¶éŸ³æ€â€æ—¶æ’å…¥å ä½æ°”æ³¡ï¼Œé¿å…æ»‘åŠ¨å–æ¶ˆåæ®‹ç•™â€œè¯†åˆ«ä¸­...â€
                self.holdToTalkPlaceholderMessageId = self.onSendImmediate?()

                // 4) å¯åŠ¨å‘é€å¾ªç¯ï¼šæŒç»­ drain PCM bytes -> WS binary
                let backlog = await MainActor.run { self.holdToTalkPCMBacklog }
                self.holdToTalkSendLoopTask = Task.detached(priority: .userInitiated) { [weak self] in
                    guard let self else { return }
                    while !Task.isCancelled {
                        // è‹¥è¿™ä¸€è½®å·²è¢«æ›¿ä»£ï¼Œåœæ­¢
                        let stillValid = await MainActor.run { self.holdToTalkGeneration == gen && self.isPreCapturingHoldToTalk }
                        if !stillValid { break }

                        // 1) ä»å½•éŸ³å™¨å–å‡ºæ–°å¢ PCMï¼Œå…ˆå†™å…¥ backlogï¼ˆæ— è®º WS æ˜¯å¦å·²å°±ç»ªï¼‰
                        let drained = await MainActor.run { self.holdToTalkRecorder.drainPCMBytes() }
                        if !drained.isEmpty {
                            await MainActor.run { self.appendHoldToTalkFullPCM(drained) }
                        }
                        if let backlog, !drained.isEmpty {
                            await backlog.append(drained)
                        }

                        // 2) å°è¯•ä» backlog flush åˆ° WSï¼›å¤±è´¥ä¸ä¸¢æ•°æ®ï¼Œç•™åˆ°ä¸‹ä¸€è½®é‡è¯•
                        guard let backlog else {
                            try? await Task.sleep(nanoseconds: 30_000_000)
                            continue
                        }
                        guard let s = await MainActor.run(body: { self.holdToTalkVoiceSession }) else {
                            try? await Task.sleep(nanoseconds: 30_000_000)
                            continue
                        }

                        // æ¯è½®æœ€å¤šå‘ä¸€å°æ‰¹ï¼Œé¿å…é•¿å¾ªç¯é˜»å¡å…¶å®ƒä»»åŠ¡
                        var sentBytesThisTick = 0
                        while sentBytesThisTick < 24_576 { // ~24KB / tick
                            guard let next = await backlog.peek(maxBytes: 4096), !next.isEmpty else { break }
                            do {
                                try await s.sendPCMChunk(next)
                                await backlog.dropFirst(next.count)
                                sentBytesThisTick += next.count
                            } catch {
                                // WS è¿˜æ²¡ ready/æš‚æ—¶å¤±è´¥ï¼šä¸ dropï¼Œç•™ç»™ä¸‹æ¬¡
                                break
                            }
                        }

                        try? await Task.sleep(nanoseconds: 30_000_000) // ~33fpsï¼Œæ›´å¿«æ¨é€å‡å°‘â€œå½•éŸ³æ€åˆ‡æ¢åå»¶è¿Ÿâ€
                    }
                }

                // 5) å¯åŠ¨æ¥æ”¶å¾ªç¯ï¼šå®æ—¶æ¥æ”¶ asr_resultï¼Œå¹¶æ‰“å°ï¼ˆâ€œåå°æ‰“å°ç”¨æˆ·æµå¼è¯´è¯è½¬çš„æ–‡å­—ç»“æœâ€ï¼‰
                self.holdToTalkReceiveLoopTask = Task.detached(priority: .userInitiated) { [weak self] in
                    guard let self else { return }
                    while !Task.isCancelled {
                        let stillValid = await MainActor.run { self.holdToTalkGeneration == gen }
                        if !stillValid { break }
                        guard let s = await MainActor.run(body: { self.holdToTalkVoiceSession }) else { break }
                        do {
                            let ev = try await s.receiveEvent()
                            await MainActor.run {
                                // è‹¥è¿™ä¸€è½®å·²è¢«æ›¿ä»£ï¼Œä¸¢å¼ƒ
                                guard self.holdToTalkGeneration == gen else { return }
                                switch ev {
                                case let .asrResult(text, isFinal):
                                    self.holdToTalkLatestASRText = text
                                    self.holdToTalkLatestASRIsFinal = isFinal
                                    self.holdToTalkLatestText = text
                                    // âœ… ç”¨æˆ·æ°”æ³¡å®æ—¶è½¬å†™ï¼šç›´æ¥æ›´æ–°å ä½æ¶ˆæ¯å†…å®¹ï¼ˆä¸æ’â€œè¯†åˆ«ä¸­...â€ï¼‰
                                    if let mid = self.holdToTalkPlaceholderMessageId {
                                        let trimmed = text.trimmingCharacters(in: .whitespacesAndNewlines)
                                        if !trimmed.isEmpty {
                                            self.onUpdatePlaceholderText?(mid, text)
                                        }
                                    }
                                case let .asrComplete(text, _):
                                    self.holdToTalkLatestASRText = text
                                    self.holdToTalkLatestASRIsFinal = true
                                    self.holdToTalkLatestText = text
                                    if let mid = self.holdToTalkPlaceholderMessageId {
                                        let trimmed = text.trimmingCharacters(in: .whitespacesAndNewlines)
                                        if trimmed.isEmpty {
                                            self.onRemovePlaceholder?(mid)
                                            self.holdToTalkPlaceholderMessageId = nil
                                        } else {
                                            self.onUpdatePlaceholderText?(mid, text)
                                        }
                                    }
                                case let .taskId(tid):
                                    // âœ… ä¸æ™®é€š chat ä¸€è‡´ï¼štask_id ä¹Ÿä¼šå›å¡«åˆ° agent message.notes
                                    let chunk: [String: Any] = ["type": "task_id", "task_id": tid]
                                    let out = BackendChatService.parseChunkDelta(chunk)
                                    if !out.isEmpty {
                                        if self.holdToTalkAgentMessageId == nil {
                                            self.holdToTalkAgentMessageId = self.onBeginVoiceAgentMessage?()
                                        }
                                        if let aid = self.holdToTalkAgentMessageId {
                                            self.onApplyVoiceAgentOutput?(aid, out)
                                        }
                                    }
                                case let .other(payload):
                                    // âœ… è¯­éŸ³æ¥å£è¿”å›ä¸æ™®é€š chat ä¸€è‡´ï¼šassistant çš„ markdown/tool/card éƒ½èµ°åŒä¸€å¥—ç»“æ„åŒ–å›å¡«
                                    let role = (payload["role"] as? String)?.lowercased() ?? ""
                                    let type = (payload["type"] as? String)?.lowercased() ?? ""
                                    let looksLikeAssistantChunk = (
                                        role == "assistant" || role == "agent"
                                        || (role.isEmpty && (type == "markdown" || type == "tool" || type == "card" || type == "task_id"))
                                    )
                                    guard looksLikeAssistantChunk else { break }
                                    let out = BackendChatService.parseChunkDelta(payload)
                                    guard !out.isEmpty else { break }
                                    if self.holdToTalkAgentMessageId == nil {
                                        self.holdToTalkAgentMessageId = self.onBeginVoiceAgentMessage?()
                                    }
                                    if let aid = self.holdToTalkAgentMessageId {
                                        self.onApplyVoiceAgentOutput?(aid, out)
                                    }
                                case .done:
                                    if let aid = self.holdToTalkAgentMessageId {
                                        self.onEndVoiceAgentMessage?(aid)
                                    }
                                    // done åé‡Šæ”¾ WS/éº¦å…‹é£èµ„æº
                                    Task.detached { [weak self] in
                                        await self?.closeHoldToTalkSession()
                                    }
                                case .cancelled, .stopped:
                                    if let aid = self.holdToTalkAgentMessageId {
                                        self.onEndVoiceAgentMessage?(aid)
                                    }
                                    Task.detached { [weak self] in
                                        await self?.closeHoldToTalkSession()
                                    }
                                case let .error(_, message):
                                    self.onVoiceAgentError?(self.holdToTalkAgentMessageId, message)
                                    Task.detached { [weak self] in
                                        await self?.closeHoldToTalkSession()
                                    }
                                }
                            }
                        } catch {
                            // WS æ–­å¼€/è§£æå¼‚å¸¸ï¼šç»“æŸæ¥æ”¶å¾ªç¯
                            break
                        }
                    }
                }
                await MainActor.run {
                    // å¯åŠ¨æˆåŠŸåæ¸…ç©ºå¼•ç”¨ï¼Œé¿å…ä¸‹ä¸€è½®è¯¯ cancel æ—§ä»»åŠ¡
                    if self.holdToTalkGeneration == gen {
                        self.holdToTalkStartupTask = nil
                    }
                }
            } catch {
                // å¯åŠ¨å¤±è´¥ï¼šé‡Šæ”¾èµ„æºå¹¶æ¸…ç†å ä½æ¶ˆæ¯
                let placeholderId = self.holdToTalkPlaceholderMessageId
                self.holdToTalkPlaceholderMessageId = nil
                self.holdToTalkVoiceSession = nil
                _ = self.holdToTalkRecorder.stop(discard: true)
                if let placeholderId {
                    self.onRemovePlaceholder?(placeholderId)
                }
            }
        }
    }

    /// é•¿æŒ‰è¢«åˆ¤å®š/éœ€è¦å±•ç¤º UI æ—¶è°ƒç”¨ï¼šæŠŠ overlay æ‹‰èµ·æ¥ï¼Œä½†ä¸ä¼šé‡å¯æ”¶éŸ³ã€‚
    func revealHoldToTalkOverlayIfPossible() {
        guard !isAgentTyping else { return }
        guard isPreCapturingHoldToTalk else { return }
        guard !isRecording else { return }

        // æ³¨æ„ï¼šä¸å»ºè®®åœ¨ withAnimation ä¸­ä¿®æ”¹ isRecordingï¼Œ
        // å¦åˆ™æŸäº›å¸ƒå±€è®¡ç®—å¯èƒ½ä¼šåœ¨åŠ¨ç”»ä¸­é€”å‘ç”Ÿå˜åŒ–ã€‚
        isAnimatingRecordingEntry = true
        isAnimatingRecordingExit = false
        isRecording = true
        isCanceling = false
        // recordingTranscript ç»´æŒå½“å‰å€¼ï¼ˆå¯èƒ½å·²ç»æœ‰éƒ¨åˆ†è½¬å†™ï¼‰

        // è§¦æ„Ÿï¼šä»…åœ¨â€œçœŸæ­£è¿›å…¥å½•éŸ³æ€â€æ—¶ç»™ä¸€æ¬¡ç¡®è®¤ï¼ˆæŒ‰ä¸‹ç¬é—´å·²æœ‰ä¸€æ¬¡è§¦æ„Ÿï¼Œè¿™é‡Œæ›´è½»ä¸€ç‚¹ï¼‰
        HapticFeedback.impact(style: .medium, intensity: 0.7)
    }

    /// è½»ç‚¹/æ»‘åŠ¨æ‰“æ–­æ—¶è°ƒç”¨ï¼šåœæ­¢é¢„æ”¶éŸ³ä¸”ä¸å±•ç¤º overlayã€ä¸å‘é€ä»»ä½•æ–‡å­—ã€‚
    func stopHoldToTalkPreCaptureIfNeeded() {
        guard isPreCapturingHoldToTalk else { return }
        isPreCapturingHoldToTalk = false
        holdToTalkASRTask?.cancel()
        holdToTalkASRTask = nil
        holdToTalkSendLoopTask?.cancel()
        holdToTalkSendLoopTask = nil
        holdToTalkStartupTask?.cancel()
        holdToTalkStartupTask = nil

        let placeholderId = holdToTalkPlaceholderMessageId
        holdToTalkPlaceholderMessageId = nil

        holdToTalkLatestText = ""
        holdToTalkLatestASRText = ""
        holdToTalkLatestASRIsFinal = false
        holdToTalkAgentMessageId = nil
        recordingTranscript = ""
        audioPower = 0.0
        isCanceling = false

        holdToTalkReceiveLoopTask?.cancel()
        holdToTalkReceiveLoopTask = nil
        holdToTalkPCMBacklog = nil
        holdToTalkFullPCM = Data()

        Task.detached { [weak self] in
            guard let self else { return }
            if let s = await MainActor.run(body: { self.holdToTalkVoiceSession }) {
                try? await s.sendCancel()
                await s.close()
            }
            _ = await MainActor.run { self.holdToTalkRecorder.stop(discard: true) }
            await MainActor.run { self.holdToTalkVoiceSession = nil }
        }

        if let placeholderId {
            onRemovePlaceholder?(placeholderId)
        }

        print("[HoldToTalk] pre-capture stopped (no overlay)")
    }
    
    func updateDragLocation(_ location: CGPoint, in bounds: CGRect) {
        // ç®€å•çš„å‘ä¸Šæ‹–åŠ¨å–æ¶ˆåˆ¤å®š
        // å¦‚æœæ‰‹æŒ‡å‘ä¸Šç§»åŠ¨è¶…è¿‡ä¸€å®šè·ç¦»ï¼ˆä¾‹å¦‚è¾“å…¥æ¡†ä¸Šæ–¹ 50ptï¼‰
        if location.y < -50 {
            if !isCanceling {
                withAnimation { isCanceling = true }
            }
        } else {
            if isCanceling {
                withAnimation { isCanceling = false }
            }
        }
    }

    // MARK: - Dictation backfill

    /// æŠŠå½•éŸ³è½¬å†™ç»“æœå†™å›è¾“å…¥æ¡†ï¼š
    /// - è‹¥è¾“å…¥æ¡†å·²æœ‰æ–‡å­—ï¼šè¿½åŠ ï¼ˆä¸åšæ‰‹åŠ¨æ‹¼ç©ºæ ¼/trimï¼Œä¿æŒåŸå§‹æ–‡æœ¬ï¼‰
    /// - è‹¥è¾“å…¥æ¡†ä¸ºç©ºï¼šç›´æ¥å†™å…¥
    private func applyPendingDictationTextToInputIfNeeded() {
        guard let text = pendingDictationTextForInput,
              !text.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty
        else { return }
        pendingDictationTextForInput = nil

        if inputText.isEmpty {
            inputText = text
        } else {
            inputText = inputText + text
        }
    }
}

// MARK: - Backend hold-to-talk finalize

private extension ChatInputViewModel {
    /// æ¾æ‰‹åï¼šåœæ­¢æœ¬åœ°å½•éŸ³ï¼Œå¹¶å‘ŠçŸ¥åç«¯éŸ³é¢‘å‘é€å®Œæ¯•ã€‚
    /// æ³¨æ„ï¼šä¸ä¼šå…³é—­ WSï¼ˆAI å›å¤ä»ä¼šç»§ç»­ä»è¯¥ WS è¿”å›ï¼‰ã€‚
    func finishBackendHoldToTalkAndSendAudioDone(genAtStop: Int) async {
        // 1) åœæ­¢æœ¬åœ° PCM é‡‡é›†ï¼ŒæŠŠå°¾å·´ drain å‡ºæ¥ï¼ˆé¿å…æœ€åä¸€æˆªä¸¢å­—ï¼‰
        let remainingPCM = holdToTalkRecorder.stop(discard: false)
        if !remainingPCM.isEmpty {
            appendHoldToTalkFullPCM(remainingPCM)
        }

        // è‹¥è¿™ä¸€è½®å·²è¢«æ›¿ä»£ï¼Œç›´æ¥é€€å‡ºï¼ˆé¿å…å½±å“æ–°ä¸€è½®ï¼‰
        guard holdToTalkGeneration == genAtStop else { return }

        // 1.5) æµ‹è¯•ï¼šæŠŠå®Œæ•´ PCM è½ç›˜ä¸º wavï¼Œå¹¶æ’å…¥ä¸€æ¡â€œç”¨æˆ·éŸ³é¢‘æ°”æ³¡â€
        emitHoldToTalkRawAudioBubbleIfNeeded(genAtStop: genAtStop)

        // 2) å‘é€å‰©ä½™ PCM + audio_record_doneï¼ˆæºå¸¦å®¢æˆ·ç«¯ä¾§æœ€åä¸€æ¬¡ asr_result å…œåº•ï¼‰
        guard let session = holdToTalkVoiceSession else { return }
        do {
            // æŠŠæœ€åä¸€æ®µä¹Ÿå¡è¿› backlogï¼Œå†ç»Ÿä¸€ flushï¼ˆé¿å… sendLoop å–æ¶ˆæ—¶ä¸¢åœ¨â€œå·² drain æœªå‘â€çš„ä¸­é—´æ€ï¼‰
            if let backlog = holdToTalkPCMBacklog {
                await backlog.append(remainingPCM)
                try await flushPCMBacklog(backlog, session: session, maxChunkBytes: 4096)
            } else {
                // ä¸€æ¬¡æ€§å‘è¶…å¤§ data å¯èƒ½å¯¼è‡´ WS åˆ†ç‰‡/å†…å­˜å‹åŠ›ï¼Œè¿™é‡Œåšå°åˆ†å—
                try await sendPCMInChunks(remainingPCM, session: session, chunkSize: 4096)
            }
            try await session.sendAudioRecordDone(asrText: holdToTalkLatestASRText, isFinal: holdToTalkLatestASRIsFinal)
        } catch {
            // ignoreï¼šåç»­ç”±æœåŠ¡ç«¯ asr_complete/assistant chunk å…œåº•
        }
    }

    /// å…³é—­è¯­éŸ³ WS å¹¶æ¸…ç†èµ„æºï¼ˆå¹‚ç­‰ï¼‰
    func closeHoldToTalkSession() async {
        // å…ˆæŠ“å–å¼•ç”¨ï¼Œé¿å…å¹¶å‘é‡å¤ close
        let session = holdToTalkVoiceSession
        holdToTalkVoiceSession = nil

        holdToTalkSendLoopTask?.cancel()
        holdToTalkSendLoopTask = nil
        holdToTalkReceiveLoopTask?.cancel()
        holdToTalkReceiveLoopTask = nil
        holdToTalkStartupTask?.cancel()
        holdToTalkStartupTask = nil
        holdToTalkASRTask?.cancel()
        holdToTalkASRTask = nil

        holdToTalkPCMBacklog = nil
        holdToTalkPlaceholderMessageId = nil
        holdToTalkAgentMessageId = nil
        holdToTalkLatestText = ""
        holdToTalkLatestASRText = ""
        holdToTalkLatestASRIsFinal = false
        recordingTranscript = ""
        isHoldToTalkRecognizing = false
        isPreCapturingHoldToTalk = false

        // ç¡®ä¿éº¦å…‹é£é‡Šæ”¾ï¼ˆstop() å…·å¤‡å¹‚ç­‰ç‰¹æ€§ï¼‰
        _ = holdToTalkRecorder.stop(discard: true)

        if let session {
            await session.close()
        }
    }

    func sendPCMInChunks(_ data: Data, session: ChatVoiceInputService.Session, chunkSize: Int) async throws {
        guard !data.isEmpty else { return }
        let size = max(256, chunkSize)
        var offset = 0
        while offset < data.count {
            let end = min(offset + size, data.count)
            let sub = data.subdata(in: offset..<end)
            try await session.sendPCMChunk(sub)
            offset = end
        }
    }

    func flushPCMBacklog(_ backlog: PCMBacklog, session: ChatVoiceInputService.Session, maxChunkBytes: Int) async throws {
        let chunkSize = max(256, maxChunkBytes)
        while true {
            guard let next = await backlog.peek(maxBytes: chunkSize), !next.isEmpty else { break }
            try await session.sendPCMChunk(next)
            await backlog.dropFirst(next.count)
        }
    }

    func appendHoldToTalkFullPCM(_ bytes: Data) {
        guard !bytes.isEmpty else { return }
        holdToTalkFullPCM.append(bytes)
        // å…œåº•ä¸Šé™ï¼šçº¦ 4 åˆ†é’Ÿï¼ˆ32KB/s -> 7.5MBï¼‰ï¼Œè¶³å¤Ÿæµ‹è¯•ä¸”é¿å…æç«¯æƒ…å†µä¸‹å†…å­˜æ— é™å¢é•¿
        let cap = 8 * 1024 * 1024
        if holdToTalkFullPCM.count > cap {
            holdToTalkFullPCM = Data(holdToTalkFullPCM.suffix(cap))
        }
    }

    func emitHoldToTalkRawAudioBubbleIfNeeded(genAtStop: Int) {
        // ä»…åœ¨æœ‰æ•°æ®ã€ä¸”ä»æ˜¯åŒä¸€è½®æ—¶è§¦å‘
        guard holdToTalkGeneration == genAtStop else { return }
        guard !holdToTalkFullPCM.isEmpty else { return }

        // å¿«ç…§ + æ¸…ç©ºï¼ˆé¿å…ä¸‹ä¸€è½®ä¸²æ•°æ®ï¼‰
        let pcmSnapshot = holdToTalkFullPCM
        holdToTalkFullPCM = Data()

        Task.detached(priority: .utility) { [weak self] in
            guard let self else { return }
            do {
                let wav = WAV16PCMWriter.makeWAV(pcm16leMono: pcmSnapshot, sampleRate: 16_000)
                let url = FileManager.default.temporaryDirectory
                    .appendingPathComponent("holdtotalk-\(UUID().uuidString)")
                    .appendingPathExtension("wav")
                try wav.write(to: url, options: [.atomic])
                await MainActor.run {
                    self.onInsertHoldToTalkRawAudio?(url)
                }
            } catch {
                // æµ‹è¯•åŠŸèƒ½ï¼šå†™å¤±è´¥å°±å¿½ç•¥ï¼Œä¸å½±å“åŸé“¾è·¯
            }
        }
    }
}

// MARK: - WAV writer (16-bit PCM, little-endian, mono)

private enum WAV16PCMWriter {
    static func makeWAV(pcm16leMono: Data, sampleRate: Int) -> Data {
        let numChannels: UInt16 = 1
        let bitsPerSample: UInt16 = 16
        let byteRate = UInt32(sampleRate) * UInt32(numChannels) * UInt32(bitsPerSample) / 8
        let blockAlign = numChannels * (bitsPerSample / 8)
        let dataSize = UInt32(pcm16leMono.count)
        let riffChunkSize = UInt32(36) + dataSize

        var out = Data()
        out.reserveCapacity(44 + pcm16leMono.count)

        // RIFF header
        out.append(contentsOf: [0x52, 0x49, 0x46, 0x46]) // "RIFF"
        out.appendLE(riffChunkSize)
        out.append(contentsOf: [0x57, 0x41, 0x56, 0x45]) // "WAVE"

        // fmt subchunk
        out.append(contentsOf: [0x66, 0x6D, 0x74, 0x20]) // "fmt "
        out.appendLE(UInt32(16)) // PCM fmt chunk size
        out.appendLE(UInt16(1)) // audio format = 1 (PCM)
        out.appendLE(numChannels)
        out.appendLE(UInt32(sampleRate))
        out.appendLE(byteRate)
        out.appendLE(blockAlign)
        out.appendLE(bitsPerSample)

        // data subchunk
        out.append(contentsOf: [0x64, 0x61, 0x74, 0x61]) // "data"
        out.appendLE(dataSize)
        out.append(pcm16leMono)
        return out
    }
}

private extension Data {
    mutating func appendLE(_ v: UInt16) {
        var x = v.littleEndian
        Swift.withUnsafeBytes(of: &x) { append(contentsOf: $0) }
    }
    mutating func appendLE(_ v: UInt32) {
        var x = v.littleEndian
        Swift.withUnsafeBytes(of: &x) { append(contentsOf: $0) }
    }
}

// MARK: - PCM backlog actor

/// çº¿ç¨‹å®‰å…¨çš„ PCM å¾…å‘é€ç¼“å†²ï¼Œè§£å†³ WS åˆæœŸ send() å¤±è´¥å¯¼è‡´çš„â€œå‰é¢æ¼å­—â€ã€‚
private actor PCMBacklog {
    private var data = Data()

    func append(_ bytes: Data) {
        guard !bytes.isEmpty else { return }
        data.append(bytes)
        // å…œåº•ä¸Šé™ï¼šé¿å…æç«¯ç½‘ç»œå·®å¯¼è‡´å†…å­˜æ— é™å¢é•¿ï¼ˆçº¦ 10 ç§’ 32KB/s -> 320KBï¼‰
        let cap = 512 * 1024
        if data.count > cap {
            // ä¿ç•™æœ€æ–°éƒ¨åˆ†ï¼ˆæ›´è´´è¿‘ç”¨æˆ·å½“å‰è¯´è¯ï¼‰ï¼ŒåŒæ—¶é˜²æ­¢ OOM
            // æ³¨æ„ï¼šData ç»è¿‡ slice/suffix å startIndex å¯èƒ½ä¸æ˜¯ 0ï¼›
            // è¿™é‡Œå¼ºåˆ¶ç”Ÿæˆâ€œæ–°çš„ Dataâ€ï¼Œé¿å…åç»­ç”¨ Range(Int) å–å­æ•°æ®è§¦å‘è¶Šç•Œ trapã€‚
            data = Data(data.suffix(cap))
        }
    }

    /// å–å‡ºå¤´éƒ¨ä¸€æ®µï¼ˆä¸ç§»é™¤ï¼‰ï¼›è‹¥ä¸ºç©ºè¿”å› nilã€‚
    func peek(maxBytes: Int) -> Data? {
        guard !data.isEmpty else { return nil }
        let n = max(0, maxBytes)
        if n <= 0 { return nil }
        let end = min(n, data.count)
        // Data.startIndex ä¸ä¸€å®šæ˜¯ 0ï¼ˆå°¤å…¶æ˜¯ slice åï¼‰ï¼Œå¿…é¡»ç”¨ Index è®¡ç®—èŒƒå›´
        let endIndex = data.index(data.startIndex, offsetBy: end)
        return data.subdata(in: data.startIndex..<endIndex)
    }

    func dropFirst(_ count: Int) {
        guard count > 0, !data.isEmpty else { return }
        let n = min(count, data.count)
        data.removeFirst(n)
    }
}
