import Foundation
@preconcurrency import AVFoundation

/// æŒ‰ä½è¯´è¯ï¼šç›´æ¥é‡‡é›†éº¦å…‹é£ PCMï¼ˆç»Ÿä¸€è¾“å‡º 16k/16bit/mono çš„ Int16 PCM bytesï¼‰
final class HoldToTalkPCMRecorder: ObservableObject {
    enum RecorderError: LocalizedError {
        case micPermissionDenied
        case cannotCreateConverter
        case engineStartFailed

        var errorDescription: String? {
            switch self {
            case .micPermissionDenied: return "éº¦å…‹é£æƒé™æœªæˆæƒ"
            case .cannotCreateConverter: return "æ— æ³•åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨"
            case .engineStartFailed: return "éŸ³é¢‘å¼•æ“å¯åŠ¨å¤±è´¥"
            }
        }
    }

    @Published private(set) var isRecording: Bool = false
    @Published private(set) var audioLevel: Float = 0

    private let audioQueue = DispatchQueue(label: "com.molymemo.holdtotalk.pcm")
    private let engine = AVAudioEngine()
    private var converter: AVAudioConverter?

    // ä»…åœ¨ audioQueue å†…è¯»å†™ï¼Œé¿å…ä¸éŸ³é¢‘ tap çº¿ç¨‹æŠ¢æ•°æ®
    private var pcmData = Data()
    private var bytesPerFrame: Int = 2 // int16 mono
    /// ä»…åœ¨ audioQueue è®¿é—®ï¼šç”¨äºå†³å®šæ˜¯å¦æ¥å—/å¤„ç† tap çš„éŸ³é¢‘æ•°æ®ã€‚
    /// ä¸èƒ½ç”¨ @Published çš„ isRecording åšè·¨çº¿ç¨‹åˆ¤å®šï¼Œå¦åˆ™ stop() å…ˆç½® false ä¼šå¯¼è‡´"å°¾å·´"è¢«ä¸¢ã€‚
    private var captureActive: Bool = false

    // è½»é‡è‡ªåŠ¨å¢ç›Šï¼ˆAGCï¼‰ï¼šè®©å°å£°è¯´è¯æ›´å®¹æ˜“è¢«åç«¯è¯†åˆ«
    // - ä»…åœ¨ audioQueue è®¿é—®
    private var agcGain: Float = 1.0
    private let agcMaxGain: Float = 6.0
    private let agcSmoothing: Float = 0.15 // è¶Šå¤§è¶Š"æ•æ„Ÿ"ï¼Œè¶Šå°è¶Šç¨³å®š

    // AudioSession é€€åœºå»¶è¿Ÿï¼šé¿å…"åˆšæ¾æ‰‹å°±ç«‹åˆ»ç¬¬äºŒæ®µå½•éŸ³"æ—¶é‡å¤ setActive(true/false) å¯¼è‡´å¡é¡¿/éŸ³æµªæ…¢åŠæ‹
    private var pendingDeactivateWorkItem: DispatchWorkItem?
    private let sessionDeactivateDelay: TimeInterval = 0.6
    
    // é¢„çƒ­çŠ¶æ€ï¼šå‡å°‘é¦–æ¬¡å½•éŸ³çš„å¯åŠ¨å»¶è¿Ÿ
    private var isSessionWarmedUp: Bool = false
    private var lastSessionConfigTime: Date?

    // MARK: - Main-thread publishing helpers
    // SwiftUI è¦æ±‚ @Published çš„å˜æ›´å¿…é¡»åœ¨ä¸»çº¿ç¨‹å‘å¸ƒï¼Œå¦åˆ™ä¼šå‡ºç°ç´«è‰²è¿è¡Œæ—¶æŠ¥è­¦ã€‚
    private func publishIsRecording(_ value: Bool) {
        if Thread.isMainThread {
            isRecording = value
        } else {
            // å…³é”®ï¼šä¸è¦ç”¨ main.sync é˜»å¡éŸ³é¢‘é‡‡é›†å¯åŠ¨ï¼ˆä¸»çº¿ç¨‹å¯èƒ½åœ¨æ»šåŠ¨/åŠ¨ç”»ä¸­å¾ˆå¿™ï¼‰
            DispatchQueue.main.async { [weak self] in
                self?.isRecording = value
            }
        }
    }

    private func publishAudioLevel(_ value: Float) {
        if Thread.isMainThread {
            audioLevel = value
        } else {
            // åŒä¸Šï¼šé¿å…é˜»å¡éŸ³é¢‘çº¿ç¨‹
            DispatchQueue.main.async { [weak self] in
                self?.audioLevel = value
            }
        }
    }

    func start() async throws {
        if isRecording {
            _ = stop(discard: false)
        }

        // è‹¥åˆš stop è¿‡ï¼šå–æ¶ˆ AudioSession å»¶è¿Ÿé€€åœºï¼Œä¿è¯äºŒæ¬¡å½•éŸ³ç«‹åˆ»èµ·
        if let item = pendingDeactivateWorkItem {
            item.cancel()
            pendingDeactivateWorkItem = nil
        }

        let granted = await requestMicPermission()
        guard granted else { throw RecorderError.micPermissionDenied }

        try configureAudioSessionForRecording()

        // åœ¨éŸ³é¢‘é˜Ÿåˆ—é‡Œåˆ‡åˆ°"æ¥æ”¶æ•°æ®"æ€ï¼Œé¿å…ä¸ tap çš„å¼‚æ­¥å†™å…¥ç«äº‰
        audioQueue.sync {
            pcmData = Data()
            captureActive = true
            agcGain = 1.0
        }
        // @Published æ›´æ–°å›åˆ°ä¸»çº¿ç¨‹ï¼Œé¿å… SwiftUI æŠ¥è­¦
        publishAudioLevel(0)

        let inputNode = engine.inputNode
        let bus = 0
        inputNode.removeTap(onBus: bus)

        let inFormat = inputNode.inputFormat(forBus: bus)
        guard let outFormat = AVAudioFormat(commonFormat: .pcmFormatInt16, sampleRate: 16_000, channels: 1, interleaved: false) else {
            throw RecorderError.cannotCreateConverter
        }
        guard let conv = AVAudioConverter(from: inFormat, to: outFormat) else {
            throw RecorderError.cannotCreateConverter
        }
        converter = conv
        bytesPerFrame = MemoryLayout<Int16>.size // mono

        let outFrameCapacity: AVAudioFrameCount = 2048
        guard let outBuffer = AVAudioPCMBuffer(pcmFormat: outFormat, frameCapacity: outFrameCapacity) else {
            throw RecorderError.cannotCreateConverter
        }

        publishIsRecording(true)
        print("[HoldToTalk] ğŸ™ï¸ start PCM engine capture (in=\(inFormat.sampleRate)Hz ch=\(inFormat.channelCount))")

        // æ•è·å¿…è¦å¯¹è±¡ï¼Œé¿å…åœ¨ @Sendable é—­åŒ…é‡Œç›´æ¥è§¦ç¢° main-actor çŠ¶æ€
        let q = audioQueue
        // ä½¿ç”¨æ›´å°çš„ bufferSizeï¼ˆ512 è€Œé 1024ï¼‰ä»¥è·å¾—æ›´å¿«çš„å›è°ƒé¢‘ç‡ï¼Œå‡å°‘å»¶è¿Ÿ
        inputNode.installTap(onBus: bus, bufferSize: 512, format: inFormat) { [weak self] buffer, _ in
            // 1) è®¡ç®—éŸ³é‡ï¼ˆç”¨è¾“å…¥ buffer æ›´å®æ—¶ï¼‰ï¼Œå›åˆ°ä¸»çº¿ç¨‹æ›´æ–° UI
            let level = Self.computeLevel(buffer: buffer)
            DispatchQueue.main.async { [weak self] in
                self?.audioLevel = level
            }

            // 2) è½¬æˆ 16k/int16/monoï¼Œå¹¶æŠŠ bytes è¿½åŠ åˆ°å†…å­˜ï¼ˆè¿½åŠ æ“ä½œæ”¾åˆ°ä¸²è¡Œé˜Ÿåˆ—ï¼Œé¿å…æ•°æ®ç«äº‰ï¼‰
            q.async { [weak self] in
                guard let self else { return }
                guard self.captureActive else { return }
                guard let converter = self.converter else { return }

                outBuffer.frameLength = 0
                var error: NSError?
                // å…³é”®ï¼šAVAudioConverter åœ¨ä¸€æ¬¡ convert() è¿‡ç¨‹ä¸­å¯èƒ½ä¼šå¤šæ¬¡è°ƒç”¨ inputBlock æ‹‰å–è¾“å…¥ã€‚
                // å¦‚æœæˆ‘ä»¬æ¯æ¬¡éƒ½è¿”å›åŒä¸€ä¸ª bufferï¼Œä¼šå¯¼è‡´åŒä¸€æ®µéŸ³é¢‘è¢«"é‡å¤å–‚å…¥"ï¼Œå¬èµ·æ¥åƒå›å£°/é‡å½±ã€‚
                // æ­£ç¡®åšæ³•ï¼šå¯¹"å•ä¸ªè¾“å…¥ buffer çš„è½¬æ¢"ï¼Œåªæä¾›ä¸€æ¬¡è¾“å…¥ï¼Œåç»­è¿”å› endOfStreamã€‚
                var didProvideInput = false
                converter.reset() // é¿å…è·¨ buffer çš„å†…éƒ¨çŠ¶æ€æ®‹ç•™ï¼ˆæ›´ç¡®å®šçš„å•æ®µè½¬æ¢ï¼‰
                let status = converter.convert(to: outBuffer, error: &error) { _, outStatus -> AVAudioBuffer? in
                    if didProvideInput {
                        outStatus.pointee = .endOfStream
                        return nil
                    }
                    didProvideInput = true
                    outStatus.pointee = .haveData
                    return buffer
                }
                if let error {
                    print("[HoldToTalk] âŒ PCM convert error -> \(error.domain)(\(error.code)) \(error.localizedDescription)")
                    return
                }
                guard status == .haveData, outBuffer.frameLength > 0 else { return }
                guard let p = outBuffer.int16ChannelData?[0] else { return }
                let byteCount = Int(outBuffer.frameLength) * self.bytesPerFrame
                let frames = Int(outBuffer.frameLength)
                let bytes = self.applyAutoGainIfNeeded(samples: p, frames: frames)
                self.pcmData.append(bytes)
            }
        }

        engine.prepare()
        do {
            try engine.start()
        } catch {
            publishIsRecording(false)
            throw RecorderError.engineStartFailed
        }
    }

    /// - Returns: 16k/16bit/mono PCM bytesï¼ˆInt16 little-endianï¼‰
    func stop(discard: Bool) -> Data {
        let wasRecording = isRecording
        // å…ˆæŠŠå¯¹å¤–çŠ¶æ€åˆ‡å›"éå½•éŸ³"ï¼ˆUI éœ€è¦ç«‹åˆ»æ¢å¤ï¼‰ï¼Œä½†ä¸è¦å½±å“éŸ³é¢‘é˜Ÿåˆ—é‡Œ"å°¾å·´"å¤„ç†ã€‚
        publishIsRecording(false)
        publishAudioLevel(0)

        // å…ˆåœå¼•æ“/ç§»é™¤ tapï¼šé˜»æ­¢æ–° buffer è¿›å…¥é˜Ÿåˆ—
        if engine.isRunning {
            engine.stop()
        }
        engine.inputNode.removeTap(onBus: 0)

        // ç­‰å¾…éŸ³é¢‘é˜Ÿåˆ—æŠŠå·²ç»æ’é˜Ÿçš„è½¬æ¢ä»»åŠ¡è·‘å®Œï¼Œå†ä¸€æ¬¡æ€§æ”¶å£æ•°æ®ã€‚
        // è¿™ä¸€æ­¥æ˜¯"æ¾æ‰‹å°¾éƒ¨ä¸åå­—"çš„å…³é”®ã€‚
        let bytes: Data = audioQueue.sync {
            captureActive = false
            let out = pcmData
            pcmData = Data()
            return out
        }

        // è½¬æ¢å™¨ä¸å†éœ€è¦ï¼ˆæ”¾åˆ°é˜Ÿåˆ— drain ä¹‹åå†æ¸…ç©ºï¼Œé¿å… queued task è¯»åˆ° nilï¼‰
        converter = nil

        // AudioSession å»¶è¿Ÿé€€åœºï¼šå¦‚æœç”¨æˆ·é©¬ä¸Šå¼€å§‹ä¸‹ä¸€æ®µå½•éŸ³ï¼Œå°±é¿å…é¢‘ç¹ setActive(true/false)
        pendingDeactivateWorkItem?.cancel()
        let item = DispatchWorkItem {
            do {
                try AVAudioSession.sharedInstance().setActive(false, options: [.notifyOthersOnDeactivation])
            } catch {
                // ignore
            }
        }
        pendingDeactivateWorkItem = item
        DispatchQueue.main.asyncAfter(deadline: .now() + sessionDeactivateDelay, execute: item)

        if wasRecording {
            if discard {
                print("[HoldToTalk] ğŸ›‘ stop PCM capture (discard)")
            } else {
                print("[HoldToTalk] ğŸ›‘ stop PCM capture bytes=\(bytes.count)")
            }
        }

        return discard ? Data() : bytes
    }

    /// å½•éŸ³è¿‡ç¨‹ä¸­å–å‡ºå½“å‰å·²ç¼“å­˜çš„ PCM bytesï¼Œå¹¶æ¸…ç©ºå†…éƒ¨ç¼“å­˜ï¼ˆç”¨äºæµå¼å‘é€ï¼‰ã€‚
    /// - Returns: 16k/16bit/mono PCM bytesï¼ˆInt16 little-endianï¼‰
    func drainPCMBytes() -> Data {
        audioQueue.sync {
            let out = pcmData
            pcmData = Data()
            return out
        }
    }

    // MARK: - Helpers

    /// æŠŠ Int16 PCM åšè½»é‡è‡ªåŠ¨å¢ç›Šå¹¶é™å¹…ï¼Œæå‡å°å£°è¯´è¯çš„å¯è¯†åˆ«æ€§ã€‚
    /// - Important: ä»…åœ¨ audioQueue è°ƒç”¨
    private func applyAutoGainIfNeeded(samples: UnsafePointer<Int16>, frames: Int) -> Data {
        guard frames > 0 else { return Data() }

        var peak: Int32 = 0
        for i in 0..<frames {
            let v = Int32(samples[i])
            let a = v >= 0 ? v : -v
            if a > peak { peak = a }
        }

        // è¿‘ä¼¼é™éŸ³ï¼šä¸åšå¢ç›Šï¼Œé¿å…æŠŠåº•å™ªæ”¾å¤§
        if peak < 200 {
            return Data(bytes: samples, count: frames * bytesPerFrame)
        }

        // åŸºäºå³°å€¼çš„åˆ†æ®µå¢ç›Šï¼šç®€å•ã€ç¨³å®šã€CPU ä½
        let desired: Float = {
            if peak < 1_000 { return 6.0 }
            if peak < 2_000 { return 4.0 }
            if peak < 4_000 { return 3.0 }
            if peak < 8_000 { return 2.0 }
            if peak < 12_000 { return 1.6 }
            return 1.0
        }()

        let clippedDesired = min(max(desired, 1.0), agcMaxGain)
        agcGain = agcGain * (1 - agcSmoothing) + clippedDesired * agcSmoothing

        let gain = agcGain
        var out = Data(count: frames * bytesPerFrame)
        out.withUnsafeMutableBytes { rawBuf in
            guard let dst = rawBuf.bindMemory(to: Int16.self).baseAddress else { return }
            for i in 0..<frames {
                let v = Float(samples[i]) * gain
                let clamped = max(-32768.0, min(32767.0, v))
                dst[i] = Int16(clamped)
            }
        }
        return out
    }

    private func requestMicPermission() async -> Bool {
        await withCheckedContinuation { continuation in
            if #available(iOS 17.0, *) {
                AVAudioApplication.requestRecordPermission { granted in
                    continuation.resume(returning: granted)
                }
            } else {
                AVAudioSession.sharedInstance().requestRecordPermission { granted in
                    continuation.resume(returning: granted)
                }
            }
        }
    }

    private func configureAudioSessionForRecording() throws {
        let audioSession = AVAudioSession.sharedInstance()
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦å®Œæ•´é…ç½®ï¼šå¦‚æœæœ€è¿‘åˆšé…ç½®è¿‡ä¸” session ä»å¤„äºé¢„æœŸçŠ¶æ€ï¼Œè·³è¿‡è€—æ—¶çš„ setCategory
        let needsFullConfig: Bool = {
            // é¦–æ¬¡æˆ–è¶…è¿‡ 2 ç§’æœªé…ç½®ï¼šéœ€è¦å®Œæ•´é…ç½®
            guard isSessionWarmedUp,
                  let lastTime = lastSessionConfigTime,
                  Date().timeIntervalSince(lastTime) < 2.0 else {
                return true
            }
            // æ£€æŸ¥å½“å‰çŠ¶æ€æ˜¯å¦å·²ç»æ˜¯æˆ‘ä»¬éœ€è¦çš„
            let currentCategory = audioSession.category
            let currentMode = audioSession.mode
            return currentCategory != .playAndRecord || currentMode != .voiceChat
        }()
        
        if needsFullConfig {
            // æç®€"é€šè¯å¼"é…ç½®ï¼ˆæ¥è¿‘ç³»ç»Ÿç”µè¯çš„ä½“éªŒï¼‰ï¼š
            // - å¿…é¡»ä½¿ç”¨ playAndRecord + voiceChat æ‰æœ‰ç³»ç»Ÿçš„è¯­éŸ³å¤„ç†ï¼ˆAEC/NS/AGCï¼‰
            // - ä¸å¼€å¯ defaultToSpeakerï¼šé»˜è®¤èµ°å¬ç­’ï¼ˆreceiverï¼‰ï¼Œé¿å…å¤–æ”¾å›çŒé€ æˆå›å£°
            // - ä¸ºäº†æœ€å¤§åŒ–æ¶ˆé™¤å›å£°ï¼Œè¿™é‡Œä¸å¯ç”¨è“ç‰™é€šè¯ï¼ˆallowBluetoothHFPï¼‰ï¼Œå¼ºåˆ¶ç”¨å†…ç½®éº¦å…‹é£+å¬ç­’
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.duckOthers])

            // å¼ºåˆ¶èµ°å¬ç­’ï¼ˆä¸æ˜¯æ‰¬å£°å™¨ï¼‰
            try audioSession.overrideOutputAudioPort(.none)

            // å°½é‡å›ºå®šç”¨å†…ç½®éº¦å…‹é£ï¼ˆé¿å…è“ç‰™/å¤šè·¯ç”±å¯¼è‡´çš„"ä¾§éŸ³/å›å£°"ä½“æ„Ÿï¼‰
            if #available(iOS 13.0, *) {
                if let builtInMic = audioSession.availableInputs?.first(where: { $0.portType == .builtInMic }) {
                    try? audioSession.setPreferredInput(builtInMic)
                }
            }

            try? audioSession.setPreferredSampleRate(48_000)
            try? audioSession.setPreferredInputNumberOfChannels(1)
        }
        
        // IO Buffer Duration è®¾ç½®æ›´å°ä»¥å‡å°‘å»¶è¿Ÿï¼ˆ5ms vs 10msï¼‰
        // æ³¨æ„ï¼šå¤ªå°å¯èƒ½å¯¼è‡´æŸäº›è®¾å¤‡ CPU å‹åŠ›å¢å¤§ï¼Œ5ms æ˜¯æ¯”è¾ƒå¥½çš„å¹³è¡¡ç‚¹
        try? audioSession.setPreferredIOBufferDuration(0.005)
        try audioSession.setActive(true)
        
        isSessionWarmedUp = true
        lastSessionConfigTime = Date()
    }
    
    /// é¢„çƒ­ AudioSessionï¼šåœ¨è¿›å…¥èŠå¤©ç•Œé¢æ—¶è°ƒç”¨ï¼Œå‡å°‘é¦–æ¬¡å½•éŸ³çš„å¯åŠ¨å»¶è¿Ÿ
    func warmUpSession() {
        // å¦‚æœå·²ç»é¢„çƒ­è¿‡ä¸”æ—¶é—´ä¸é•¿ï¼Œè·³è¿‡
        if isSessionWarmedUp, let lastTime = lastSessionConfigTime, Date().timeIntervalSince(lastTime) < 5.0 {
            return
        }
        
        Task.detached(priority: .background) {
            let audioSession = AVAudioSession.sharedInstance()
            do {
                // åªåš category é…ç½®ï¼Œä¸åš setActiveï¼ˆé¿å…å½±å“å…¶ä»–éŸ³é¢‘ï¼‰
                try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.duckOthers])
                try? audioSession.setPreferredSampleRate(48_000)
                try? audioSession.setPreferredInputNumberOfChannels(1)
                try? audioSession.setPreferredIOBufferDuration(0.005)
                await MainActor.run {
                    self.isSessionWarmedUp = true
                    self.lastSessionConfigTime = Date()
                }
                print("[HoldToTalk] AudioSession warmed up")
            } catch {
                // ignore
            }
        }
    }

    private static func computeLevel(buffer: AVAudioPCMBuffer) -> Float {
        // ä¼˜å…ˆ floatChannelDataï¼›æ²¡æœ‰å°±é€€åŒ–
        if let ch = buffer.floatChannelData?[0] {
            let frames = Int(buffer.frameLength)
            guard frames > 0 else { return 0 }
            var sum: Float = 0
            var peak: Float = 0
            for i in 0..<frames {
                let s = abs(ch[i])
                sum += s * s
                peak = max(peak, s)
            }
            let rms = sqrt(sum / Float(frames))
            let raw = rms * 0.6 + peak * 0.4
            // æ”¾å®½å°å£°é—¨é™ï¼šè®©æ›´å°å£°ä¹Ÿèƒ½é©±åŠ¨ UIï¼ˆä¸å½±å“å®é™… PCM æ•°æ®ï¼‰
            let noiseFloor: Float = 0.008
            let normalized = max(0, raw - noiseFloor) / max(0.0001, 1 - noiseFloor)
            // å¢åŠ å¢ç›Šï¼šå°å£°æ›´å®¹æ˜“"èµ·æ³¢å½¢"ï¼Œå¤§å£°ä»ä¼šè¢« clamp åˆ° 1.0
            let gained = min(normalized * 6.8, 1.0)
            return pow(gained, 0.55)
        }
        return 0
    }
}
