import Foundation
@preconcurrency import AVFoundation

/// æŒ‰ä½è¯´è¯ï¼šç›´æ¥é‡‡é›†éº¦å…‹é£ PCMï¼ˆç»Ÿä¸€è¾“å‡º 16k/16bit/mono çš„ Int16 PCM bytesï¼‰
final class HoldToTalkPCMRecorder: ObservableObject {
    enum RecorderError: LocalizedError {
        case micPermissionDenied
        case cannotCreateConverter
        case engineStartFailed

        var errorDescription: String? {
            switch self {
            case .micPermissionDenied: return "éº¦å…‹é£æƒé™æœªæˆæƒ"
            case .cannotCreateConverter: return "æ— æ³•åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨"
            case .engineStartFailed: return "éŸ³é¢‘å¼•æ“å¯åŠ¨å¤±è´¥"
            }
        }
    }

    @Published private(set) var isRecording: Bool = false
    @Published private(set) var audioLevel: Float = 0

    private let audioQueue = DispatchQueue(label: "com.molymemo.holdtotalk.pcm")
    private let engine = AVAudioEngine()
    private var converter: AVAudioConverter?

    // ä»…åœ¨ audioQueue å†…è¯»å†™ï¼Œé¿å…ä¸éŸ³é¢‘ tap çº¿ç¨‹æŠ¢æ•°æ®
    private var pcmData = Data()
    private var bytesPerFrame: Int = 2 // int16 mono

    func start() async throws {
        if isRecording {
            _ = stop(discard: false)
        }

        let granted = await requestMicPermission()
        guard granted else { throw RecorderError.micPermissionDenied }

        try configureAudioSessionForRecording()

        pcmData = Data()
        audioLevel = 0

        let inputNode = engine.inputNode
        let bus = 0
        inputNode.removeTap(onBus: bus)

        let inFormat = inputNode.inputFormat(forBus: bus)
        guard let outFormat = AVAudioFormat(commonFormat: .pcmFormatInt16, sampleRate: 16_000, channels: 1, interleaved: false) else {
            throw RecorderError.cannotCreateConverter
        }
        guard let conv = AVAudioConverter(from: inFormat, to: outFormat) else {
            throw RecorderError.cannotCreateConverter
        }
        converter = conv
        bytesPerFrame = MemoryLayout<Int16>.size // mono

        let outFrameCapacity: AVAudioFrameCount = 2048
        guard let outBuffer = AVAudioPCMBuffer(pcmFormat: outFormat, frameCapacity: outFrameCapacity) else {
            throw RecorderError.cannotCreateConverter
        }

        isRecording = true
        print("[HoldToTalk] ğŸ™ï¸ start PCM engine capture (in=\(inFormat.sampleRate)Hz ch=\(inFormat.channelCount))")

        // æ•è·å¿…è¦å¯¹è±¡ï¼Œé¿å…åœ¨ @Sendable é—­åŒ…é‡Œç›´æ¥è§¦ç¢° main-actor çŠ¶æ€
        let q = audioQueue
        inputNode.installTap(onBus: bus, bufferSize: 1024, format: inFormat) { [weak self] buffer, _ in
            // 1) è®¡ç®—éŸ³é‡ï¼ˆç”¨è¾“å…¥ buffer æ›´å®æ—¶ï¼‰ï¼Œå›åˆ°ä¸»çº¿ç¨‹æ›´æ–° UI
            let level = Self.computeLevel(buffer: buffer)
            DispatchQueue.main.async { [weak self] in
                self?.audioLevel = level
            }

            // 2) è½¬æˆ 16k/int16/monoï¼Œå¹¶æŠŠ bytes è¿½åŠ åˆ°å†…å­˜ï¼ˆè¿½åŠ æ“ä½œæ”¾åˆ°ä¸²è¡Œé˜Ÿåˆ—ï¼Œé¿å…æ•°æ®ç«äº‰ï¼‰
            q.async { [weak self] in
                guard let self else { return }
                guard self.isRecording else { return }
                guard let converter = self.converter else { return }

                outBuffer.frameLength = 0
                var error: NSError?
                let status = converter.convert(to: outBuffer, error: &error) { _, outStatus -> AVAudioBuffer? in
                    outStatus.pointee = .haveData
                    return buffer
                }
                if let error {
                    print("[HoldToTalk] âŒ PCM convert error -> \(error.domain)(\(error.code)) \(error.localizedDescription)")
                    return
                }
                guard status == .haveData, outBuffer.frameLength > 0 else { return }
                guard let p = outBuffer.int16ChannelData?[0] else { return }
                let byteCount = Int(outBuffer.frameLength) * self.bytesPerFrame
                self.pcmData.append(Data(bytes: p, count: byteCount))
            }
        }

        engine.prepare()
        do {
            try engine.start()
        } catch {
            isRecording = false
            throw RecorderError.engineStartFailed
        }
    }

    /// - Returns: 16k/16bit/mono PCM bytesï¼ˆInt16 little-endianï¼‰
    func stop(discard: Bool) -> Data {
        let wasRecording = isRecording
        isRecording = false
        audioLevel = 0

        if engine.isRunning {
            engine.stop()
        }
        engine.inputNode.removeTap(onBus: 0)
        converter = nil

        // æ”¶å› AudioSession
        do {
            try AVAudioSession.sharedInstance().setActive(false, options: [.notifyOthersOnDeactivation])
        } catch {
            // ignore
        }

        // ç­‰å¾…éŸ³é¢‘é˜Ÿåˆ—æŠŠå°¾å·´æ”¶å¹²å‡€ï¼Œé¿å…â€œæœ€åä¸€æ®µâ€ä¸¢å¤±
        let bytes: Data = audioQueue.sync {
            let out = pcmData
            pcmData = Data()
            return out
        }

        if wasRecording {
            if discard {
                print("[HoldToTalk] ğŸ›‘ stop PCM capture (discard)")
            } else {
                print("[HoldToTalk] ğŸ›‘ stop PCM capture bytes=\(bytes.count)")
            }
        }

        return discard ? Data() : bytes
    }

    // MARK: - Helpers

    private func requestMicPermission() async -> Bool {
        await withCheckedContinuation { continuation in
            if #available(iOS 17.0, *) {
                AVAudioApplication.requestRecordPermission { granted in
                    continuation.resume(returning: granted)
                }
            } else {
                AVAudioSession.sharedInstance().requestRecordPermission { granted in
                    continuation.resume(returning: granted)
                }
            }
        }
    }

    private func configureAudioSessionForRecording() throws {
        let audioSession = AVAudioSession.sharedInstance()
        do {
            do {
                try audioSession.setCategory(
                    .playAndRecord,
                    // ä¼˜å…ˆå¯ç”¨è¯­éŸ³å¤„ç†ï¼ˆAEC/NSï¼‰ï¼šèƒ½æ˜æ˜¾å‡å°‘â€œä½™éŸ³/å›å£°â€å¯¼è‡´çš„å è¯
                    mode: .voiceChat,
                    // æŒ‰ä½è¯´è¯åœºæ™¯ä¸éœ€è¦å¼ºåˆ¶æ‰¬å£°å™¨è¾“å‡ºï¼›é¿å…å¤–æ”¾å›çŒåˆ°éº¦å…‹é£é€ æˆé‡å¤
                    options: [.duckOthers, .allowBluetoothHFP]
                )
            } catch {
                try audioSession.setCategory(
                    .playAndRecord,
                    mode: .spokenAudio,
                    options: [.duckOthers, .allowBluetoothHFP]
                )
            }
            try? audioSession.setPreferredSampleRate(48_000)
            try? audioSession.setPreferredInputNumberOfChannels(1)
            try? audioSession.setPreferredIOBufferDuration(0.01)
            try audioSession.setActive(true)
        } catch {
            throw error
        }
    }

    private static func computeLevel(buffer: AVAudioPCMBuffer) -> Float {
        // ä¼˜å…ˆ floatChannelDataï¼›æ²¡æœ‰å°±é€€åŒ–
        if let ch = buffer.floatChannelData?[0] {
            let frames = Int(buffer.frameLength)
            guard frames > 0 else { return 0 }
            var sum: Float = 0
            var peak: Float = 0
            for i in 0..<frames {
                let s = abs(ch[i])
                sum += s * s
                peak = max(peak, s)
            }
            let rms = sqrt(sum / Float(frames))
            let raw = rms * 0.6 + peak * 0.4
            // æ”¾å®½å°å£°é—¨é™ï¼šè®©æ›´å°å£°ä¹Ÿèƒ½é©±åŠ¨ UIï¼ˆä¸å½±å“å®é™… PCM æ•°æ®ï¼‰
            let noiseFloor: Float = 0.008
            let normalized = max(0, raw - noiseFloor) / max(0.0001, 1 - noiseFloor)
            // å¢åŠ å¢ç›Šï¼šå°å£°æ›´å®¹æ˜“â€œèµ·æ³¢å½¢â€ï¼Œå¤§å£°ä»ä¼šè¢« clamp åˆ° 1.0
            let gained = min(normalized * 6.8, 1.0)
            return pow(gained, 0.55)
        }
        return 0
    }
}


