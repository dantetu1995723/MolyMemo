import UIKit

/// åˆ†ç±»ç»“æœï¼ˆåŒ…å«ç½®ä¿¡åº¦ï¼‰
struct ClassificationResult {
    let category: ScreenshotCategory
    let confidence: Double  // 0.0 ~ 1.0
    
    /// æ˜¯å¦éœ€è¦ç”¨æˆ·ç¡®è®¤ï¼ˆç½®ä¿¡åº¦ä½äºé˜ˆå€¼ï¼‰
    var needsConfirmation: Bool {
        return confidence < 0.7
    }
}

/// æˆªå›¾å¿«é€Ÿåˆ†ç±»æœåŠ¡
/// åœ¨ Intent é˜¶æ®µå¿«é€Ÿåˆ¤æ–­æˆªå›¾å±äºå“ªä¸ªæ¨¡å—ï¼ˆå¾…åŠ/æŠ¥é”€/äººè„‰ï¼‰
struct ScreenshotClassifier {
    
    enum ClassifierError: Error {
        case invalidResponse
        case parseError
    }
    
    /// å¿«é€Ÿåˆ†ç±»æˆªå›¾
    /// - Parameter image: å¾…åˆ†ç±»çš„æˆªå›¾
    /// - Returns: åˆ†ç±»ç»“æœï¼ˆåŒ…å«ç½®ä¿¡åº¦ï¼‰
    static func classifyScreenshot(image: UIImage) async throws -> ClassificationResult {
        print("ğŸ” å¼€å§‹å¿«é€Ÿåˆ†ç±»æˆªå›¾...")

        // æç¤ºè¯ - å¿«é€Ÿåˆ†ç±»ï¼ˆåŒ…å«ç½®ä¿¡åº¦ï¼‰
        let prompt = """
        ä½ æ˜¯ä¸€ä¸ªå›¾ç‰‡åˆ†ç±»ä¸“å®¶ï¼Œéœ€è¦å¿«é€Ÿåˆ¤æ–­æˆªå›¾å±äºä»¥ä¸‹å“ªä¸ªç±»åˆ«ï¼š
        
        1. å¾…åŠ (todo) - åŒ…å«ä»»åŠ¡ã€æ—¥ç¨‹ã€ä¼šè®®ã€æé†’ç­‰ä¿¡æ¯
        2. æŠ¥é”€ (expense) - åŒ…å«å‘ç¥¨ã€æ”¶æ®ã€æ¶ˆè´¹è®°å½•ã€å¼€ç¥¨äºŒç»´ç ç­‰
        3. äººè„‰ (contact) - åŒ…å«åç‰‡ã€è”ç³»æ–¹å¼ã€ä¸ªäººä¿¡æ¯ç­‰
        4. æœªçŸ¥ (unknown) - æ— æ³•æ˜ç¡®åˆ†ç±»
        
        åˆ¤æ–­æ ‡å‡†ï¼š
        - å¦‚æœå›¾ç‰‡ä¸­æœ‰å‘ç¥¨ã€æ”¶æ®ã€ä»·æ ¼ã€é‡‘é¢ã€å¼€ç¥¨äºŒç»´ç  â†’ expense
        - å¦‚æœå›¾ç‰‡ä¸­æœ‰æ—¥ç¨‹ã€æ—¶é—´å®‰æ’ã€ä¼šè®®é€šçŸ¥ã€ä»»åŠ¡åˆ—è¡¨ â†’ todo
        - å¦‚æœå›¾ç‰‡ä¸­æœ‰å§“åã€ç”µè¯ã€å…¬å¸ã€èŒä½ã€åç‰‡ â†’ contact
        - å¦‚æœæ— æ³•æ˜ç¡®åˆ¤æ–­ â†’ unknown
        
        è¿”å›æ ¼å¼ï¼šåˆ†ç±»|ç½®ä¿¡åº¦
        ä¾‹å¦‚ï¼štodo|0.9 æˆ– expense|0.6 æˆ– unknown|0.3
        ç½®ä¿¡åº¦èŒƒå›´ï¼š0.0-1.0ï¼Œè¶Šé«˜è¡¨ç¤ºè¶Šç¡®å®š
        åªè¿”å›è¿™ä¸€è¡Œï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
        """
        
        // å‹ç¼©å›¾ç‰‡
        let resizedImage = resizeImage(image, maxSize: 1024)  // ä½¿ç”¨è¾ƒå°å°ºå¯¸åŠ å¿«é€Ÿåº¦

        let raw = try await BackendAIService.generateText(
            prompt: prompt,
            images: [resizedImage],
            mode: .work
        )

        // è§£æåˆ†ç±»ç»“æœï¼ˆæ ¼å¼ï¼šcategory|confidenceï¼‰
        let trimmedContent = raw.trimmingCharacters(in: .whitespacesAndNewlines).lowercased()
        print("ğŸ“Š AIåˆ†ç±»ç»“æœ: \(trimmedContent)")
        
        let components = trimmedContent.split(separator: "|")
        guard !components.isEmpty else { throw ClassifierError.parseError }
        let categoryString = String(components.first ?? "unknown")
        let confidenceString = components.count > 1 ? String(components[1]) : "0.5"
        let confidence = Double(confidenceString) ?? 0.5
        
        let category: ScreenshotCategory
        if categoryString.contains("todo") {
            category = .todo
        } else if categoryString.contains("expense") {
            category = .expense
        } else if categoryString.contains("contact") {
            category = .contact
        } else {
            category = .unknown
        }
        
        let result = ClassificationResult(category: category, confidence: confidence)
        print("âœ… åˆ†ç±»å®Œæˆ: \(category.rawValue), ç½®ä¿¡åº¦: \(String(format: "%.2f", confidence))")
        
        return result
    }
    
    // è¾…åŠ©æ–¹æ³•ï¼šå‹ç¼©å›¾ç‰‡
    private static func resizeImage(_ image: UIImage, maxSize: CGFloat) -> UIImage {
        let size = image.size
        let maxDimension = max(size.width, size.height)
        
        if maxDimension <= maxSize {
            return image
        }
        
        let scale = maxSize / maxDimension
        let newSize = CGSize(width: size.width * scale, height: size.height * scale)
        
        UIGraphicsBeginImageContextWithOptions(newSize, false, 1.0)
        image.draw(in: CGRect(origin: .zero, size: newSize))
        let resizedImage = UIGraphicsGetImageFromCurrentImageContext() ?? image
        UIGraphicsEndImageContext()
        
        return resizedImage
    }
}

